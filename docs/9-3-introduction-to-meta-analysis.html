<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="9.3 Introduction to Meta-Analysis | Improving Your Statistical Inferences" />
<meta property="og:type" content="book" />
<meta property="og:url" content="http://themethodsection.com/ebook/" />
<meta property="og:image" content="http://themethodsection.com/ebook/images/cover.jpg" />
<meta property="og:description" content="Online textbook to Improve Your Statistical Inferences" />


<meta name="author" content="Daniel Lakens" />

<meta name="date" content="2020-08-15" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Online textbook to Improve Your Statistical Inferences">

<title>9.3 Introduction to Meta-Analysis | Improving Your Statistical Inferences</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>



</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html">Welcome</a>
<a href="contents.html">Contents</a>
<a href="1-pvalue.html"><span class="toc-section-number">1</span> <em>p</em>-values</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="1-1-what-is-a-p-value.html"><span class="toc-section-number">1.1</span> What is a <em>p</em>-value?</a>
<a href="1-2-fisher-vs-neyman.html.-neyman"><span class="toc-section-number">1.2</span> Fisher vs. Neyman</a>
<a href="1-3-preventing-common-misconceptions-about-p-values.html"><span class="toc-section-number">1.3</span> Preventing common misconceptions about <em>p</em>-values</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="1-3-preventing-common-misconceptions-about-p-values.html"><span class="toc-section-number">1.3.1</span> Misunderstanding 1: A non-significant <em>p</em>-value means that the null hypothesis is true</a>
<a href="1-3-preventing-common-misconceptions-about-p-values.html."><span class="toc-section-number">1.3.2</span> Misunderstanding 2: A significant <em>p</em>-value means that the null hypothesis is false.</a>
<a href="1-3-preventing-common-misconceptions-about-p-values.html"><span class="toc-section-number">1.3.3</span> Misunderstanding 3: A significant <em>p</em>-value means that a practically important effect has been discovered</a>
<a href="1-3-preventing-common-misconceptions-about-p-values.html."><span class="toc-section-number">1.3.4</span> Misunderstanding 4: If you have observed a significant finding, the probability that you have made a Type 1 error (a false positive) is 5%.</a>
<a href="1-3-preventing-common-misconceptions-about-p-values.html."><span class="toc-section-number">1.3.5</span> Misunderstanding 5: One minus the <em>p</em>-value is the probability that the effect will replicate when repeated.</a>
</div>
</li>
</ul>
<a href="1-4-which-p-values-can-you-expect.html"><span class="toc-section-number">1.4</span> Which <em>p</em>-values can you expect?</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="1-4-which-p-values-can-you-expect.html"><span class="toc-section-number">1.4.1</span> Lindley’s paradox</a>
</div>
</li>
</ul>
</div>
</li>
</ul>
<a href="2-power.html"><span class="toc-section-number">2</span> Sample size justification</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="2-1-measuring-the-entire-population.html"><span class="toc-section-number">2.1</span> Measuring the Entire Population</a>
<a href="2-2-feasibility.html"><span class="toc-section-number">2.2</span> Feasibility</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="2-2-feasibility.html"><span class="toc-section-number">2.2.1</span> The smallest effect size that can be statistically significant</a>
<a href="2-2-feasibility.html"><span class="toc-section-number">2.2.2</span> Compute the width of the confidence interval around the effect size</a>
<a href="2-2-feasibility.html"><span class="toc-section-number">2.2.3</span> Plot a sensitivity power analysis</a>
<a href="2-2-feasibility.html."><span class="toc-section-number">2.2.4</span> Reporting a feasibility justification.</a>
</div>
</li>
</ul>
<a href="2-3-a-priori-power-analysis.html"><span class="toc-section-number">2.3</span> A-priori power analysis</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="2-3-a-priori-power-analysis.html."><span class="toc-section-number">2.3.1</span> Performing a power analysis.</a>
<a href="2-3-a-priori-power-analysis.html"><span class="toc-section-number">2.3.2</span> Justifying the effect size used in an a-priori power analysis</a>
<a href="2-3-a-priori-power-analysis.html"><span class="toc-section-number">2.3.3</span> Justifying the error rates used in an a-priori power analysis</a>
<a href="2-3-a-priori-power-analysis.html"><span class="toc-section-number">2.3.4</span> Some advice when using G*Power</a>
<a href="2-3-a-priori-power-analysis.html"><span class="toc-section-number">2.3.5</span> A-priori power analysis for the absence of an effect</a>
<a href="2-3-a-priori-power-analysis.html."><span class="toc-section-number">2.3.6</span> Reporting an a-priori power analysis.</a>
</div>
</li>
</ul>
<a href="2-4-compromisepower.html"><span class="toc-section-number">2.4</span> Compromise power analysis</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="2-4-compromisepower.html"><span class="toc-section-number">2.4.1</span> Reporting a compromise power analysis</a>
</div>
</li>
</ul>
<a href="2-5-observedpower.html"><span class="toc-section-number">2.5</span> Observed (post-hoc) power analysis</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="2-5-observedpower.html"><span class="toc-section-number">2.5.1</span> What to do if your editor asks for post-hoc power?</a>
</div>
</li>
</ul>
<a href="2-6-designing-efficient-studies.html"><span class="toc-section-number">2.6</span> Designing efficient studies</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="2-6-designing-efficient-studies.html."><span class="toc-section-number">2.6.1</span> Use directional tests where relevant.</a>
<a href="2-6-designing-efficient-studies.html"><span class="toc-section-number">2.6.2</span> Use sequential analysis whenever possible</a>
<a href="2-6-designing-efficient-studies.html"><span class="toc-section-number">2.6.3</span> Increase your alpha level</a>
<a href="2-6-designing-efficient-studies.html"><span class="toc-section-number">2.6.4</span> Use within designs where possible</a>
<a href="2-6-designing-efficient-studies.html"><span class="toc-section-number">2.6.5</span> Remove statistical variation where possible</a>
<a href="2-6-designing-efficient-studies.html"><span class="toc-section-number">2.6.6</span> Use Bayesian statistics with informed priors</a>
</div>
</li>
</ul>
<a href="2-7-what-if-best-practices-are-not-enough.html"><span class="toc-section-number">2.7</span> What if best practices are not enough?</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="2-7-what-if-best-practices-are-not-enough.html"><span class="toc-section-number">2.7.1</span> Ask for more money in your grant proposals</a>
<a href="2-7-what-if-best-practices-are-not-enough.html"><span class="toc-section-number">2.7.2</span> Improve management</a>
<a href="2-7-what-if-best-practices-are-not-enough.html"><span class="toc-section-number">2.7.3</span> Change what is expected from PhD students</a>
<a href="2-7-what-if-best-practices-are-not-enough.html"><span class="toc-section-number">2.7.4</span> Get answers collectively</a>
</div>
</li>
</ul>
<a href="2-8-planning-for-precision.html"><span class="toc-section-number">2.8</span> Planning for precision</a>
</div>
</li>
</ul>
<a href="3-questions.html"><span class="toc-section-number">3</span> Asking Statistical Questions</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="3-1-do-you-really-want-to-test-a-hypothesis.html"><span class="toc-section-number">3.1</span> Do You Really Want to Test a Hypothesis?</a>
<a href="3-2-goals-of-tests.html"><span class="toc-section-number">3.2</span> Goals of tests</a>
</div>
</li>
</ul>
<a href="4-errorcontrol.html"><span class="toc-section-number">4</span> Error Control</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="4-1-why-you-dont-need-to-adjust-your-alpha-level-for-all-tests-youll-do-in-your-lifetime-.html."><span class="toc-section-number">4.1</span> Why you don’t need to adjust your alpha level for all tests you’ll do in your lifetime.</a>
<a href="4-2-why-banning-p-values-might-not-solve-our-problems-.html."><span class="toc-section-number">4.2</span> Why banning p-values might not solve our problems.</a>
<a href="4-3-error-control-in-exploratory-anovas-the-how-and-the-why.html"><span class="toc-section-number">4.3</span> Error Control in Exploratory ANOVA’s: The How and the Why</a>
</div>
</li>
</ul>
<a href="5-effectsizesCI.html"><span class="toc-section-number">5</span> Effect Sizes and Confidence Intervals</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="5-1-effect-sizes.html"><span class="toc-section-number">5.1</span> Effect sizes</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="5-1-effect-sizes.html"><span class="toc-section-number">5.1.1</span> The Facebook experiment</a>
</div>
</li>
</ul>
<a href="5-2-cohend.html"><span class="toc-section-number">5.2</span> Cohen’s <em>d</em></a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="5-2-cohend.html"><span class="toc-section-number">5.2.1</span> Correcting for Bias</a>
</div>
</li>
</ul>
<a href="5-3-r-correlations.html"><span class="toc-section-number">5.3</span> <em>r</em> (correlations)</a>
<a href="5-4-confint.html"><span class="toc-section-number">5.4</span> Confidence Intervals</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="5-4-confint.html.-samples"><span class="toc-section-number">5.4.1</span> Population vs. Samples</a>
<a href="5-4-confint.html"><span class="toc-section-number">5.4.2</span> The relation between confidence intervals and <em>p</em>-values</a>
<a href="5-4-confint.html"><span class="toc-section-number">5.4.3</span> The Standard Error and 95% Confidence Intervals</a>
<a href="5-4-confint.html"><span class="toc-section-number">5.4.4</span> Overlapping Confidence Intervals</a>
<a href="5-4-confint.html"><span class="toc-section-number">5.4.5</span> Prediction Intervals</a>
<a href="5-4-confint.html"><span class="toc-section-number">5.4.6</span> Capture Percentages</a>
</div>
</li>
</ul>
<a href="5-5-computing-confidence-intervals-around-effect-sizes.html"><span class="toc-section-number">5.5</span> Computing Confidence Intervals around Effect Sizes</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="5-5-computing-confidence-intervals-around-effect-sizes.html"><span class="toc-section-number">5.5.1</span> MOTE</a>
<a href="5-5-computing-confidence-intervals-around-effect-sizes.html"><span class="toc-section-number">5.5.2</span> JASP</a>
<a href="5-5-computing-confidence-intervals-around-effect-sizes.html"><span class="toc-section-number">5.5.3</span> ESCI software</a>
<a href="5-5-computing-confidence-intervals-around-effect-sizes.html"><span class="toc-section-number">5.5.4</span> MBESS</a>
<a href="5-5-computing-confidence-intervals-around-effect-sizes.html"><span class="toc-section-number">5.5.5</span> Why should you report 90% CI for eta-squared?</a>
</div>
</li>
</ul>
</div>
</li>
</ul>
<a href="6-equivalencetest.html"><span class="toc-section-number">6</span> Equivalence Testing</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="6-1-absence-of-evidence-is-not-evidence-of-absence-.html."><span class="toc-section-number">6.1</span> Absence of evidence is not evidence of absence.</a>
<a href="6-2-justifysesoi.html"><span class="toc-section-number">6.2</span> JUstifying a smallest effect size of interest</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="6-2-justifysesoi.html"><span class="toc-section-number">6.2.1</span> Rejecting the presence of a meaningful effect</a>
</div>
</li>
</ul>
<a href="bayesian-estimation-using-rope-and-equivalence-tests-.html.">Bayesian estimation using ROPE and equivalence tests.</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="bayesian-estimation-using-rope-and-equivalence-tests-.html"><span class="toc-section-number">6.2.2</span> 95% HDI vs 90% CI</a>
<a href="bayesian-estimation-using-rope-and-equivalence-tests-.html"><span class="toc-section-number">6.2.3</span> Power analysis for Equivalence Tests</a>
<a href="bayesian-estimation-using-rope-and-equivalence-tests-.html"><span class="toc-section-number">6.2.4</span> Use of prior information</a>
<a href="bayesian-estimation-using-rope-and-equivalence-tests-.html"><span class="toc-section-number">6.2.5</span> Conclusion</a>
</div>
</li>
</ul>
</div>
</li>
</ul>
<a href="7-severity.html"><span class="toc-section-number">7</span> Severe Tests and Risky Predictions</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="7-1-testing-range-predictions.html"><span class="toc-section-number">7.1</span> Testing Range Predictions</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="7-1-testing-range-predictions.html"><span class="toc-section-number">7.1.1</span> Risky Predictions</a>
<a href="7-1-testing-range-predictions.html"><span class="toc-section-number">7.1.2</span> Systematic Noise</a>
<a href="7-1-testing-range-predictions.html"><span class="toc-section-number">7.1.3</span> Range Predictions</a>
<a href="7-1-testing-range-predictions.html"><span class="toc-section-number">7.1.4</span> Directional Tests</a>
<a href="7-1-testing-range-predictions.html"><span class="toc-section-number">7.1.5</span> Minimal Effect Tests</a>
<a href="7-1-testing-range-predictions.html"><span class="toc-section-number">7.1.6</span> Range Predictions in PRactice</a>
</div>
</li>
</ul>
<a href="7-2-verisimilitude-belief-and-progress-in-psychological-science.html"><span class="toc-section-number">7.2</span> Verisimilitude, Belief, and Progress in Psychological Science</a>
</div>
</li>
</ul>
<a href="8-sesoi.html"><span class="toc-section-number">8</span> Smallest Effect Size of Interest</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="8-1-what-would-falsify-your-theory.html"><span class="toc-section-number">8.1</span> What would falsify your theory?</a>
<a href="8-2-what-would-falsify-your-theory-in-practice.html"><span class="toc-section-number">8.2</span> What would falsify your theory in practice?</a>
<a href="8-3-specifying-a-sesoi-based-on-theory-or-costs-and-benefits.html"><span class="toc-section-number">8.3</span> Specifying a SESOI based on theory or costs and benefits</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="8-3-specifying-a-sesoi-based-on-theory-or-costs-and-benefits.html"><span class="toc-section-number">8.3.1</span> Example of a theoretically predicted SESOI</a>
<a href="8-3-specifying-a-sesoi-based-on-theory-or-costs-and-benefits.html"><span class="toc-section-number">8.3.2</span> Anchor based methods to set a SESOI</a>
<a href="8-3-specifying-a-sesoi-based-on-theory-or-costs-and-benefits.html"><span class="toc-section-number">8.3.3</span> Cost benefit analysis</a>
<a href="8-3-specifying-a-sesoi-based-on-theory-or-costs-and-benefits.html"><span class="toc-section-number">8.3.4</span> Setting the SESOI based on effects feasible to study</a>
</div>
</li>
</ul>
<a href="8-4-smalltelescopes.html"><span class="toc-section-number">8.4</span> The small telescopes approach</a>
<a href="8-5-setting-the-sesoi-based-on-resources-.html."><span class="toc-section-number">8.5</span> Setting the SESOI based on resources.</a>
<a href="8-6-setting-the-smallest-effect-size-of-interest-in-replication-studies.html"><span class="toc-section-number">8.6</span> Setting the smallest effect size of interest in replication studies</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="8-6-setting-the-smallest-effect-size-of-interest-in-replication-studies.html"><span class="toc-section-number">8.6.1</span> Setting the SESOI based on theoretical predictions</a>
<a href="8-6-setting-the-smallest-effect-size-of-interest-in-replication-studies.html"><span class="toc-section-number">8.6.2</span> Setting the smallest effect size of interest based on resources</a>
</div>
</li>
</ul>
</div>
</li>
</ul>
<a href="9-meta.html"><span class="toc-section-number">9</span> Meta-analysis</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="9-1-random-variation.html"><span class="toc-section-number">9.1</span> Random Variation</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="9-1-random-variation.html"><span class="toc-section-number">9.1.1</span> Variation in single samples</a>
<a href="9-1-random-variation.html."><span class="toc-section-number">9.1.2</span> Variance in two groups, and their difference.</a>
<a href="9-1-random-variation.html"><span class="toc-section-number">9.1.3</span> Correlations between two groups</a>
<a href="9-1-random-variation.html."><span class="toc-section-number">9.1.4</span> Confidence Intervals around Standard Deviations.</a>
</div>
</li>
</ul>
<a href="9-2-mixed.html"><span class="toc-section-number">9.2</span> Mixed Results</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="9-2-mixed.html"><span class="toc-section-number">9.2.1</span> Likelihoods of sets of studies</a>
</div>
</li>
</ul>
<a id="active-page" href="9-3-introduction-to-meta-analysis.html"><span class="toc-section-number">9.3</span> Introduction to Meta-Analysis</a><ul class="navbar"><ul class="toc-sections">
<li class="toc"><a href="#introduction-to-meta-analysis"> Introduction to Meta-Analysis</a></li>
</ul>
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="9-3-introduction-to-meta-analysis.html"><span class="toc-section-number">9.3.1</span> Single study meta-analysis</a>
<a href="9-3-introduction-to-meta-analysis.html"><span class="toc-section-number">9.3.2</span> Simulating meta-analyses of mean standardized differences</a>
<a href="9-3-introduction-to-meta-analysis.html"><span class="toc-section-number">9.3.3</span> Fixed Effect vs Random Effects</a>
<a href="9-3-introduction-to-meta-analysis.html"><span class="toc-section-number">9.3.4</span> Simulating meta-analyses for dichotomous outcomes</a>
<a href="9-3-introduction-to-meta-analysis.html"><span class="toc-section-number">9.3.5</span> Heterogeneity</a>
<a href="9-3-introduction-to-meta-analysis.html"><span class="toc-section-number">9.3.6</span> Improving the reproducibility of meta-analyses</a>
</div>
</li>
</ul>
</div>
</li>
</ul>
<a href="10-bias.html"><span class="toc-section-number">10</span> Bias detection</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1</span> Bias Detection</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.1</span> Funnel Plots</a>
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.2</span> Trim and Fill</a>
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.3</span> PET-PEESE</a>
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.4</span> P-curve Analysis</a>
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.5</span> TIVA</a>
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.6</span> Let’s Detect Some Bias!</a>
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.7</span> Introducing bias</a>
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.8</span> Bias detection techniques</a>
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.9</span> TIVA</a>
<a href="10-1-bias-detection.html"><span class="toc-section-number">10.1.10</span> Z-curve analysis</a>
<a href="bayesian-estimation-using-rope-and-equivalence-tests-.html"><span class="toc-section-number">10.1.11</span> Conclusion</a>
</div>
</li>
</ul>
</div>
</li>
</ul>
<a href="11-computationalreproducibility.html"><span class="toc-section-number">11</span> Computational Reproducibility</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="11-1-step-1-setting-up-a-github-repository.html"><span class="toc-section-number">11.1</span> Step 1: Setting up a GitHub repository</a>
<a href="11-2-step-2-cloning-your-github-repository-into-rstudio.html"><span class="toc-section-number">11.2</span> Step 2: Cloning your GitHub repository into RStudio</a>
<a href="11-3-step-3-creating-an-r-markdown-file.html"><span class="toc-section-number">11.3</span> Step 3: Creating an R Markdown file</a>
<a href="11-4-step-4-reproducible-data-analysis-in-r-studio.html"><span class="toc-section-number">11.4</span> Step 4: Reproducible Data Analysis in R Studio</a>
<a href="11-5-step-5-committing-and-pushing-to-github.html"><span class="toc-section-number">11.5</span> Step 5: Committing and Pushing to GitHub</a>
<a href="11-6-step-6-reproducible-data-analysis.html"><span class="toc-section-number">11.6</span> Step 6: Reproducible Data Analysis</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="11-6-step-6-reproducible-data-analysis.html"><span class="toc-section-number">11.6.1</span> Extra: APA formatted manuscripts in papaja</a>
</div>
</li>
</ul>
<a href="11-7-step-7-organizing-your-data-and-code.html"><span class="toc-section-number">11.7</span> Step 7: Organizing Your Data and Code</a>
<a href="11-8-step-8-archiving-your-data-and-code.html"><span class="toc-section-number">11.8</span> Step 8: Archiving Your Data and Code</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="11-8-step-8-archiving-your-data-and-code.html"><span class="toc-section-number">11.8.1</span> EXTRA: Sharing Reproducible Code on Code Ocean</a>
</div>
</li>
</ul>
<a href="11-9-some-points-for-improvement-in-computational-reproducibility.html"><span class="toc-section-number">11.9</span> Some points for improvement in computational reproducibility</a>
<a href="bayesian-estimation-using-rope-and-equivalence-tests-.html"><span class="toc-section-number">11.10</span> Conclusion</a>
</div>
</li>
</ul>
<a href="12-prereg.html"><span class="toc-section-number">12</span> Preregistration and Transparency</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="12-1-trust-in-scientists.html"><span class="toc-section-number">12.1</span> Trust in scientists</a>
<a href="12-2-the-value-of-preregistration.html"><span class="toc-section-number">12.2</span> The value of preregistration</a>
<a href="12-3-registered-reports.html"><span class="toc-section-number">12.3</span> Registered Reports</a>
<a href="12-4-preregister-your-study.html"><span class="toc-section-number">12.4</span> Preregister your study?</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="12-4-preregister-your-study.html"><span class="toc-section-number">12.4.1</span> How to preregister</a>
</div>
</li>
</ul>
<a href="12-5-what-does-a-formalized-test-of-a-prediction-look-like.html"><span class="toc-section-number">12.5</span> What Does a Formalized Test of a Prediction Look Like?</a>
<a href="12-6-are-you-ready-to-preregister-a-hypothesis-test.html"><span class="toc-section-number">12.6</span> Are you ready to preregister a hypothesis test?</a>
</div>
</li>
</ul>
<a href="13-bayes.html"><span class="toc-section-number">13</span> Bayesian statistics</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="13-1-likelihoods.html"><span class="toc-section-number">13.1</span> Likelihoods</a>
<a href="13-2-bayes-factors.html"><span class="toc-section-number">13.2</span> Bayes factors</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="13-2-bayes-factors.html"><span class="toc-section-number">13.2.1</span> Updating our belief</a>
</div>
</li>
</ul>
<a href="13-3-bayesest.html"><span class="toc-section-number">13.3</span> Bayesian Estimation</a>
</div>
</li>
</ul>
<a href="14-sequential.html"><span class="toc-section-number">14</span> Sequential Analysis</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="14-1-choosing-alpha-levels-for-sequential-analyses-.html."><span class="toc-section-number">14.1</span> Choosing alpha levels for sequential analyses.</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="14-1-choosing-alpha-levels-for-sequential-analyses-.html"><span class="toc-section-number">14.1.1</span> Pocock correction</a>
</div>
</li>
</ul>
<a href="14-2-comparing-spending-functions.html"><span class="toc-section-number">14.2</span> Comparing Spending Functions</a>
<a href="14-3-sample-size-for-sequential-designs.html"><span class="toc-section-number">14.3</span> Sample Size for Sequential Designs</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="14-3-sample-size-for-sequential-designs.html"><span class="toc-section-number">14.3.1</span> Alpha spending functions</a>
<a href="14-3-sample-size-for-sequential-designs.html"><span class="toc-section-number">14.3.2</span> Updating Boundaries During an Experiment</a>
</div>
</li>
</ul>
<a href="14-4-test-for-non-inferiority.html"><span class="toc-section-number">14.4</span> Test for (non-)inferiority</a>
<a href="14-5-stopping-for-futility.html"><span class="toc-section-number">14.5</span> Stopping for futility</a><ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="14-5-stopping-for-futility.html."><span class="toc-section-number">14.5.1</span> Sequential analyses using Bayes factors.</a>
<a href="14-5-stopping-for-futility.html."><span class="toc-section-number">14.5.2</span> Reporting results after a sequential analysis.</a>
</div>
</li>
</ul>
</div>
</li>
</ul>
<a href="15-references.html"><span class="toc-section-number">15</span> References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body>
<div id="introduction-to-meta-analysis" class="section level2">
<h2>
<span class="header-section-number">9.3</span> Introduction to Meta-Analysis</h2>
<p>Every single study is just a data-point in a future meta-analysis. If you draw small samples from a population, the mean and standard deviation in the sample can differ considerably from the mean and standard deviation in the population. There is great variability in small samples. Parameter estimates from small samples are very imprecise, and therefore the 95% confidence intervals around effect sizes are very wide. Indeed, this led Cohen (1994) to write “I suspect that the main reason [confidence intervals] are not reported is that they are so embarrassingly large!” If we want a more precise estimate of our parameter of interest, such as the mean difference or correlation in the population, we need either run extremely large single studies, or alternatively, combine data from several studies by performing a <strong>meta-analysis</strong>. The most common approach to combine studies is to perform a meta-analysis of effect size estimates.</p>
<p>You can perform a meta-analysis for a set of studies in a single article you plan to publish (often called an <strong>internal meta-analysis</strong>), or you can search the literature for multiple studies reported in as many different articles as possible, and perform a meta-analysis on all studies others have published. An excellent introduction to meta-analyses is provided in the book by Borenstein, Hedges, Higgins, and Rothstein <span class="citation">(Borenstein, <label for="tufte-mn-73" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-73" class="margin-toggle">2009<span class="marginnote">Borenstein, M. (Ed.). (2009). <em>Introduction to meta-analysis</em>. John Wiley &amp; Sons.</span>)</span>. There is commercial software you can use to perform meta-analyses, but I highly recommend <em>against</em> using such software. Almost all commercial software packages lack transparency, and do not allow you to share your analysis code and data with other researchers. In this assignment, we will be using R to perform a meta-analysis of effect sizes, using the <strong>metafor</strong> package by Viechtbauer <span class="citation">Viechtbauer (<label for="tufte-mn-74" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-74" class="margin-toggle">2010<span class="marginnote">Viechtbauer, W. (2010). Conducting meta-analyses in R with the metafor package. <em>J Stat Softw</em>, <em>36</em>(3), 1–48.</span>)</span>. An important benefit of using metafor is that your meta-analysis can be made completely reproducible.</p>
<div id="single-study-meta-analysis" class="section level3">
<h3>
<span class="header-section-number">9.3.1</span> Single study meta-analysis</h3>
<p>Let’s first begin with something you will hardly ever do in real life: a meta-analysis of a single study. This is a little silly, because a simple <em>t</em>-test or correlation will tell you the same thing – but it is educational to compare a <em>t</em>-test with a meta-analysis of a single
study, before we look at how to combine multiple studies into a meta-analysis.</p>
<p>A difference between an independent <em>t</em>-test and a meta-analysis is that a <em>t</em>-test is performed on the raw data, while a meta-analysis is performed on the effect size(s) of individual studies. The metafor R package contains a very useful function called <code>escalc</code> that can be used to calculate effect sizes, their variances, and confidence intervals around effect size estimates. So let’s start by calculating the effect size to enter into our meta-analysis. The code below (and in the R file under <strong>Part 1</strong>) can be used to calculate the <strong>standardized mean difference</strong> (SMD) from two independent groups from <strong>means</strong> (specified by m1i and m2i), <strong>standard deviations</strong> (sd1i and sd2i), and the number of observations in each group (n1i and n2i). By default, metafor calculates the effect size ‘<strong>Hedges’ g</strong>’ which is the unbiased version of Cohen’s d (see the section on <a href="5-2-cohend.html#cohend">Cohen’s d</a> in the chapter on Effect Sizes).</p>
<div class="sourceCode" id="cb85"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb85-1"><a href="9-3-introduction-to-meta-analysis.html#cb85-1"></a><span class="kw">library</span>(metafor)</span>
<span id="cb85-2"><a href="9-3-introduction-to-meta-analysis.html#cb85-2"></a><span class="co"># We calculate the standardized mean difference</span></span>
<span id="cb85-3"><a href="9-3-introduction-to-meta-analysis.html#cb85-3"></a><span class="co"># We store it as the variable g (because by default, Hedges' g is computed)</span></span>
<span id="cb85-4"><a href="9-3-introduction-to-meta-analysis.html#cb85-4"></a>g &lt;-<span class="st"> </span><span class="kw">escalc</span>(<span class="dt">measure =</span> <span class="st">"SMD"</span>,</span>
<span id="cb85-5"><a href="9-3-introduction-to-meta-analysis.html#cb85-5"></a>            <span class="dt">n1i =</span> <span class="dv">50</span>, <span class="co"># sample size in group 1 is 50 </span></span>
<span id="cb85-6"><a href="9-3-introduction-to-meta-analysis.html#cb85-6"></a>            <span class="dt">m1i =</span> <span class="fl">5.6</span>, <span class="co"># observed mean in group 1 is 5.6</span></span>
<span id="cb85-7"><a href="9-3-introduction-to-meta-analysis.html#cb85-7"></a>            <span class="dt">sd1i =</span> <span class="fl">1.2</span>, <span class="co"># observed standard deviation in group 1 is 1.2</span></span>
<span id="cb85-8"><a href="9-3-introduction-to-meta-analysis.html#cb85-8"></a>            <span class="dt">n2i =</span> <span class="dv">50</span>, <span class="co"># sample size in group 2 is 50 </span></span>
<span id="cb85-9"><a href="9-3-introduction-to-meta-analysis.html#cb85-9"></a>            <span class="dt">m2i =</span> <span class="fl">4.9</span>, <span class="co"># observed mean in group 1 is 4.9 </span></span>
<span id="cb85-10"><a href="9-3-introduction-to-meta-analysis.html#cb85-10"></a>            <span class="dt">sd2i =</span> <span class="fl">1.3</span>) <span class="co"># observed standard deviation in group 2 is 1.3</span></span>
<span id="cb85-11"><a href="9-3-introduction-to-meta-analysis.html#cb85-11"></a></span>
<span id="cb85-12"><a href="9-3-introduction-to-meta-analysis.html#cb85-12"></a><span class="co"># print results</span></span>
<span id="cb85-13"><a href="9-3-introduction-to-meta-analysis.html#cb85-13"></a>g</span></code></pre></div>
<pre><code>##       yi     vi 
## 1 0.5553 0.0415</code></pre>
<p>The output gives you Hedge’s g (under the <code>yi</code> column, which always returns the effect size, in this case the standardized mean difference) and the variance of the effect size estimate (under <code>vi</code>).</p>
<p>As explained in Borenstein, Hedges, Higgins, and Rothstein (2009, formula 4.18 to 4.24) the standardized mean difference Hedges’ g is calculated by dividing the difference between means by the pooled standard deviation, multiplied by a correction factor, J:</p>
<p><span class="math display">\[
J = (1 - \ \ 3/(4df - 1))
\]</span></p>
<p><span class="math display">\[
g = J \times \ \left( \frac{{\overline{X}}_{1} - {\overline{X}}_{2}}{S_{\text{within}}} \right)
\]</span></p>
<p>and a very good approximation of the variance of the standardized mean
difference (SMD) Hedges’ g is provided by:</p>
<p><span class="math display">\[
Vg = J^{2} \times \left( \frac{n_{1} + n_{2}}{n_{1}n_{2}} + \frac{g^{2}}{2(n_{1} + n_{2})} \right)
\]</span></p>
<p>The variance of the standardized mean difference depends only on the sample size (n1 and n2) and the value of the standardized mean difference itself. <strong>To perform the required calculations for a meta-analysis, you need the effect sizes and their variance</strong>. This means that if you have coded the effect sizes and the sample sizes (per group) from studies in the literature, you have the information you need to perform a meta-analysis.</p>
<p>You do not need to manually calculate the effect size and its variance using the two formula above – the escalc function does this for you. We can now easily perform a single study meta-analysis using the rma function in the metafor package:</p>
<div class="sourceCode" id="cb87"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb87-1"><a href="9-3-introduction-to-meta-analysis.html#cb87-1"></a><span class="co"># Perform the meta-analysis</span></span>
<span id="cb87-2"><a href="9-3-introduction-to-meta-analysis.html#cb87-2"></a>meta_res &lt;-<span class="st"> </span><span class="kw">rma</span>(yi, vi, <span class="dt">data =</span> g)</span>
<span id="cb87-3"><a href="9-3-introduction-to-meta-analysis.html#cb87-3"></a>meta_res</span></code></pre></div>
<pre><code>## 
## Fixed-Effects Model (k = 1)
## 
## I^2 (total heterogeneity / total variability):   0.00%
## H^2 (total variability / sampling variability):  1.00
## 
## Test for Heterogeneity:
## Q(df = 0) = 0.0000, p-val = 1.0000
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.5553  0.2038  2.7243  0.0064  0.1558  0.9547  ** 
## 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>Here, we see under Model Results the effect size Hedges’ g (0.5553) and the standard error (0.2038), the Z-test statistic testing the mean difference against the null-hypothesis (2.72), and the 95% confidence interval [ci.lb = 0.16; ci.ub = 0.95] around the effect size (the interval width can be specified using the ‘level =’ option). We also get the <em>p</em>-value for the test of the meta-analytic effect size against 0. In this case we can reject the null-hypothesis (<em>p</em> = 0.0064).</p>
<p>In a meta-analysis, a Z-test is used to examine whether the null-hypothesis can be rejected. This assumes a normally distributed random effect size model. Normally, you would analyze data from a single study with two groups using a <em>t</em>-test, which not surprisingly uses a <em>t</em>-distribution. If we directly compare a single-study meta-analysis, based on a Z-test, with a normal <em>t</em>-test, we will see some tiny differences in the results. We can directly calculate the effect size Hedges’ g, and the 95% confidence interval around the effect size, and the <em>t</em>-test using MOTE <span class="citation">(Buchanan et al., <label for="tufte-mn-75" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-75" class="margin-toggle">2017<span class="marginnote">Buchanan, E. M., Scofield, J., &amp; Valentine, K. D. (2017). <em>MOTE: Effect Size and Confidence Interval Calculator.</em></span>)</span>. The MOTE package uses the <em>t</em>-distribution when calculating confidence intervals around the effect size (and we can see this makes only a tiny difference compared to using the Z-distribution in a meta-analysis with 50 observations in each group).</p>
<div class="sourceCode" id="cb89"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb89-1"><a href="9-3-introduction-to-meta-analysis.html#cb89-1"></a><span class="co"># Calculate Hedges g and perform t-test with MOTE </span></span>
<span id="cb89-2"><a href="9-3-introduction-to-meta-analysis.html#cb89-2"></a>MOTE_res &lt;-<span class="st"> </span>MOTE<span class="op">::</span><span class="kw">g.ind.t</span>(<span class="dt">m1 =</span> <span class="fl">5.6</span>, </span>
<span id="cb89-3"><a href="9-3-introduction-to-meta-analysis.html#cb89-3"></a>                          <span class="dt">m2 =</span> <span class="fl">4.9</span>, </span>
<span id="cb89-4"><a href="9-3-introduction-to-meta-analysis.html#cb89-4"></a>                          <span class="dt">sd1 =</span> <span class="fl">1.2</span>, </span>
<span id="cb89-5"><a href="9-3-introduction-to-meta-analysis.html#cb89-5"></a>                          <span class="dt">sd2 =</span> <span class="fl">1.3</span>, </span>
<span id="cb89-6"><a href="9-3-introduction-to-meta-analysis.html#cb89-6"></a>                          <span class="dt">n1 =</span> <span class="dv">50</span>, </span>
<span id="cb89-7"><a href="9-3-introduction-to-meta-analysis.html#cb89-7"></a>                          <span class="dt">n2 =</span> <span class="dv">53</span>, </span>
<span id="cb89-8"><a href="9-3-introduction-to-meta-analysis.html#cb89-8"></a>                          <span class="dt">a =</span> <span class="fl">0.05</span>)</span>
<span id="cb89-9"><a href="9-3-introduction-to-meta-analysis.html#cb89-9"></a>MOTE_res<span class="op">$</span>statistic</span></code></pre></div>
<pre><code>## [1] "$t$(101) = 2.83, $p$ = 0.00553819625499491"</code></pre>
<p>The <em>t</em>-value is 2.83, and the <em>p</em>-value is 0.0055. With large enough sample sizes (which is commonly true in a meta-analysis) the difference between a Z-test and <em>t</em>-test is not really meaningful, and for this reason the Z-test is used in meta-analyses.</p>
<div class="sourceCode" id="cb91"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb91-1"><a href="9-3-introduction-to-meta-analysis.html#cb91-1"></a><span class="co"># Calculate Hedges g with MOTE </span></span>
<span id="cb91-2"><a href="9-3-introduction-to-meta-analysis.html#cb91-2"></a>MOTE_res<span class="op">$</span>estimate</span></code></pre></div>
<pre><code>## [1] "$d_{g}$ = 0.55, 95\\% CI [0.16, 0.94]"</code></pre>
<p>The results are very similar to those from the meta-analysis, with g = 0.55, 95% CI[0.16;0.94], where the effect size and the upper bound for the confidence interval differ 0.01 after rounding, because the <em>t</em>-distribution is used instead of the Z-distribution.</p>
<div class="figure">
<span id="fig:metaforest"></span>
<p class="caption marginnote shownote">
Figure 9.12: Forest plot for a single study.
</p>
<img src="Statistical_Inferences_files/figure-html/metaforest-1.png" alt="Forest plot for a single study." width="672">
</div>
<p>It is common to visualize the results of a meta-analysis using a forest plot. We see the effect size for Study 1 marked by the black square at 0.05, and the confidence interval is visualized by lines extending to –0.34 on the left and 0.44 on the right. The numbers are printed on the right-hand side of the forest plot. On the lower half of the forest plot, we see a stretched-out diamond. The diamond summarizes the meta-analytic effect size estimate, with the center being at the meta-analytic effect size estimate, and the left and right endpoints at the 95% confidence interval of the meta-analytic effect size estimate. Because we only have a single study, the meta-analytic effect size estimate is the same as the effect size estimate for our single study.</p>
<p>Meta-analyses get a bit more exciting when we are using them to analyze results
from multiple studies. When multiple studies are combined in a meta-analysis,
effect size estimates are not simply averaged, but they are <strong>weighted</strong> by the
<strong>precision</strong> of the effect size estimate, which is determined by the sample
size of the study. Thus, the larger the sample size of an individual study, the
more weight it gets in the meta-analysis, meaning that it has more influence on
the meta-analytic effect size estimate.</p>
</div>
<div id="simulating-meta-analyses-of-mean-standardized-differences" class="section level3">
<h3>
<span class="header-section-number">9.3.2</span> Simulating meta-analyses of mean standardized differences</h3>
<p>One intuitive way to learn about meta-analyses is to simulate single studies, and combine these in a meta-analysis.</p>
<div class="figure">
<span id="fig:meta-sim"></span>
<p class="caption marginnote shownote">
Figure 9.13: Forest plot for 12 simulated studies.
</p>
<img src="Statistical_Inferences_files/figure-html/meta-sim-1.png" alt="Forest plot for 12 simulated studies." width="672">
</div>
<p>We see 12 rows, one for each study, each with their own effect size and confidence interval. If you look closely, you can see the squares that indicate the effect size estimate for each study differ in size. The larger the sample size, the bigger the square. Study 3 had a relatively small sample size, which can be seen both by the small square, and the relatively wide confidence interval. Study 2 had a larger sample size, and thus a slightly larger square
and narrower confidence interval. At the bottom of the graph we find the meta-analytic effect size and its confidence interval, both visualized by a diamond and numerically. The model is referred to as a FE Model, or <strong>Fixed Effect (FE) model</strong>. The alternative approach is a RE Model, or <strong>Random Effects (RE) model</strong> (the difference is discussed below).</p>
<p>You might notice that the first two studies in the meta-analysis were not statistically significant. Take a moment to think for yourself if you would have continued this research line, after not finding an effect twice in a row. If you feel like it, run the code above several times (remove the set.seed or you will get the same result each time) and see how often this happens with a population effect size and range of sample sizes in this simulation. As should be clear from the section on <a href="9-2-mixed.html#mixed">mixed results</a>, it is important to think meta-analytically, because in the long run there will be situations where you will find one or two non-significant results early in a research line, even when there is a true effect.</p>
<p>Let’s also look at the result of the meta-analysis, which is a bit more interesting now that we have 12 studies:</p>
<div class="sourceCode" id="cb93"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb93-1"><a href="9-3-introduction-to-meta-analysis.html#cb93-1"></a>result</span></code></pre></div>
<pre><code>## 
## Fixed-Effects Model (k = 12)
## 
## I^2 (total heterogeneity / total variability):   0.00%
## H^2 (total variability / sampling variability):  0.83
## 
## Test for Heterogeneity:
## Q(df = 11) = 9.1824, p-val = 0.6051
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.3655  0.0564  6.4777  &lt;.0001  0.2549  0.4761  *** 
## 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<p>We see a test for <strong>heterogeneity</strong>, a topic we will return to <a href="9-3-introduction-to-meta-analysis.html#heterogeneity">below</a>. We see the model results, which in this specific simulation yielded a meta-analytic effect size estimate of 0.37. The confidence interval around the effect size estimate [0.25; 0.48] is much narrower than we saw before for a single study. This is because the 12 studies we simulated together have quite a large sample size, and the larger the sample size, the smaller the standard error, and thus the narrower the confidence interval is. The meta-analytic effect size estimate is statistically different from 0 (<em>p</em> &lt; 0.0001) so we can reject the null hypothesis if we use an alpha level of 0.05.</p>
</div>
<div id="fixed-effect-vs-random-effects" class="section level3">
<h3>
<span class="header-section-number">9.3.3</span> Fixed Effect vs Random Effects</h3>
<p>There are two possible models when performing a meta-analysis. One model, known as a fixed effect model, assumes there is one effect size that generates the data in all studies in the meta-analysis. This model assumes there is no variation between individual studies – all have exactly the same true effect size. The perfect example of this is the simulations we have done so far. We specified a single true effect in the population, and generated random samples
from this population effect.</p>
<p>Alternatively, one can use a model where the true effect differs in some way in each individual study. We don’t have a single true effect in the population, but a range of <strong>randomly distributed</strong> true effect sizes (hence the ‘random effects’ model). Studies differs in some way from each other (or some sets of studies differ from other sets), and their true effect sizes differ as well. Note the difference between a fixed effect model, and a random effect<strong>s</strong> model, in that the plural ‘effects’ is used only in the latter. Borenstein et al
(2009) state there are two reasons to use a fixed effect model: When all studies are functionally equivalent, and when your goal is <em>not</em> to generalize to other populations. This makes the random effects model generally the better choice, although some people have raised the concern that random-effects models give more weight to smaller studies, which can be more biased. By default, metafor will use a random effects model. We used the method=“FE” command to explicitly ask for a fixed effect model. In the meta-analyses we will simulate in the rest of this assignment we will leave out this command and simulate random effects meta-analyses.</p>
</div>
<div id="simulating-meta-analyses-for-dichotomous-outcomes" class="section level3">
<h3>
<span class="header-section-number">9.3.4</span> Simulating meta-analyses for dichotomous outcomes</h3>
<p>Although meta-analyses on mean differences are very common, a meta-analysis can be performed on many different effect sizes. To show a slightly less common example, let’s simulate a meta-analysis based on odds ratios. Sometimes the main outcome in an experiment is a dichotomous variable, such as the success or failure on a task. In such study designs we can calculate risk ratios, odds ratios, or risk differences as the effect size measure. Risk differences are sometimes judged easiest to interpret, but odds ratios are most often used for a meta-analysis because they have attractive statistical properties. An <strong>odds ratio</strong> is a ratio of two odds. To illustrate how an odds ratio is calculated, it is useful to consider the four possible outcomes in a 2 x 2 table of outcomes:</p>
<table>
<thead><tr class="header">
<th align="left"></th>
<th align="center">Success</th>
<th align="center">Failure</th>
<th align="center">N</th>
</tr></thead>
<tbody>
<tr class="odd">
<td align="left">Experimental</td>
<td align="center"><em>A</em></td>
<td align="center"><em>B</em></td>
<td align="center"><em>n1</em></td>
</tr>
<tr class="even">
<td align="left">Control</td>
<td align="center"><em>C</em></td>
<td align="center"><em>D</em></td>
<td align="center"><em>n2</em></td>
</tr>
</tbody>
</table>
<p>The odds ratio is calculated as:
<span class="math display">\[OR = \ \frac{\text{AD}}{\text{BC}}\]</span>
The meta-analysis is performed on log transformed odds ratios (because log transformed odds ratios are symmetric around 1, see Borenstein et al., 2009), and thus the log of the odds ratio is used, which has a variance which is approximated by:
<span class="math display">\[\text{Var}\left( \log\text{OR} \right) = \ \frac{1}{A} + \frac{1}{B} + \frac{1}{C} + \frac{1}{D}\]</span></p>
<p>Let’s assume that we train students in using a spaced learning strategy (they work through a textbook every week instead of cramming the week before the exam). Without such training, 70 out of 100 students succeed in passing the course after the first exam, but with this training, 80 out of 100 students
pass.</p>
<table>
<thead><tr class="header">
<th></th>
<th>Success</th>
<th>Failure</th>
<th>N</th>
</tr></thead>
<tbody>
<tr class="odd">
<td>Experimental</td>
<td>80</td>
<td>20</td>
<td>100</td>
</tr>
<tr class="even">
<td>Control</td>
<td>70</td>
<td>30</td>
<td>100</td>
</tr>
</tbody>
</table>
<p>The odds of passing in the experimental group is 80/20, or 4, while odds in the control condition are 70/30, or 2.333. The ratio of these two odds is then: 4/2.333 = 1.714, or:</p>
<p><span class="math display">\[
OR = \ \frac{80 \times 30}{20\  \times 70} = 1.714
\]</span></p>
<p>We can simulate studies with dichotomous outcomes, where we set the percentage of successes and
failures in the experimental and control condition. In the script below, by default the percentage of success in the experimental condition is 70%, and in the control condition it is 50%.</p>
<div class="sourceCode" id="cb95"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb95-1"><a href="9-3-introduction-to-meta-analysis.html#cb95-1"></a><span class="kw">library</span>(metafor)</span>
<span id="cb95-2"><a href="9-3-introduction-to-meta-analysis.html#cb95-2"></a><span class="kw">set.seed</span>(<span class="dv">5333</span>)</span>
<span id="cb95-3"><a href="9-3-introduction-to-meta-analysis.html#cb95-3"></a>nSims &lt;-<span class="st"> </span><span class="dv">12</span> <span class="co">#number of simulated experiments</span></span>
<span id="cb95-4"><a href="9-3-introduction-to-meta-analysis.html#cb95-4"></a></span>
<span id="cb95-5"><a href="9-3-introduction-to-meta-analysis.html#cb95-5"></a>pop.pr1 &lt;-<span class="st"> </span><span class="fl">0.7</span> <span class="co"># Set percentage of successes in Group 1</span></span>
<span id="cb95-6"><a href="9-3-introduction-to-meta-analysis.html#cb95-6"></a>pop.pr2 &lt;-<span class="st"> </span><span class="fl">0.5</span> <span class="co"># Set percentage of successes in Group 2</span></span>
<span id="cb95-7"><a href="9-3-introduction-to-meta-analysis.html#cb95-7"></a></span>
<span id="cb95-8"><a href="9-3-introduction-to-meta-analysis.html#cb95-8"></a>ai &lt;-<span class="st"> </span><span class="kw">numeric</span>(nSims) <span class="co"># set up empty vector for successes group 1</span></span>
<span id="cb95-9"><a href="9-3-introduction-to-meta-analysis.html#cb95-9"></a>bi &lt;-<span class="st"> </span><span class="kw">numeric</span>(nSims) <span class="co"># set up empty vector for failures group 1</span></span>
<span id="cb95-10"><a href="9-3-introduction-to-meta-analysis.html#cb95-10"></a>ci &lt;-<span class="st"> </span><span class="kw">numeric</span>(nSims) <span class="co"># set up empty vector for successes group 2</span></span>
<span id="cb95-11"><a href="9-3-introduction-to-meta-analysis.html#cb95-11"></a>di &lt;-<span class="st"> </span><span class="kw">numeric</span>(nSims) <span class="co"># set up empty vector for failures group 2</span></span>
<span id="cb95-12"><a href="9-3-introduction-to-meta-analysis.html#cb95-12"></a></span>
<span id="cb95-13"><a href="9-3-introduction-to-meta-analysis.html#cb95-13"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nSims) { <span class="co">#for each simulated experiment</span></span>
<span id="cb95-14"><a href="9-3-introduction-to-meta-analysis.html#cb95-14"></a>  n &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">30</span><span class="op">:</span><span class="dv">80</span>, <span class="dv">1</span>)</span>
<span id="cb95-15"><a href="9-3-introduction-to-meta-analysis.html#cb95-15"></a>  x &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, pop.pr1) <span class="co">#produce simulated participants (1 = success, 0 is failure)</span></span>
<span id="cb95-16"><a href="9-3-introduction-to-meta-analysis.html#cb95-16"></a>  y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, pop.pr2) <span class="co">#produce simulated participants (1 = success, 0 is failure)</span></span>
<span id="cb95-17"><a href="9-3-introduction-to-meta-analysis.html#cb95-17"></a>  ai[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(x <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="co">#Successes Group 1</span></span>
<span id="cb95-18"><a href="9-3-introduction-to-meta-analysis.html#cb95-18"></a>  bi[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(x <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="co">#Failures Group 1</span></span>
<span id="cb95-19"><a href="9-3-introduction-to-meta-analysis.html#cb95-19"></a>  ci[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(y <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="co">#Successes Group 2</span></span>
<span id="cb95-20"><a href="9-3-introduction-to-meta-analysis.html#cb95-20"></a>  di[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(y <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="co">#Failures Group 2</span></span>
<span id="cb95-21"><a href="9-3-introduction-to-meta-analysis.html#cb95-21"></a>}</span>
<span id="cb95-22"><a href="9-3-introduction-to-meta-analysis.html#cb95-22"></a></span>
<span id="cb95-23"><a href="9-3-introduction-to-meta-analysis.html#cb95-23"></a><span class="co"># Combine data into dataframe</span></span>
<span id="cb95-24"><a href="9-3-introduction-to-meta-analysis.html#cb95-24"></a>metadata &lt;-<span class="st"> </span><span class="kw">cbind</span>(ai, bi, ci, di)</span>
<span id="cb95-25"><a href="9-3-introduction-to-meta-analysis.html#cb95-25"></a><span class="co"># Create escalc object from metadata dataframe </span></span>
<span id="cb95-26"><a href="9-3-introduction-to-meta-analysis.html#cb95-26"></a>metadata &lt;-<span class="st"> </span><span class="kw">escalc</span>(<span class="dt">measure =</span> <span class="st">"OR"</span>, </span>
<span id="cb95-27"><a href="9-3-introduction-to-meta-analysis.html#cb95-27"></a>                   <span class="dt">ai =</span> ai, <span class="dt">bi =</span> bi, <span class="dt">ci =</span> ci, <span class="dt">di =</span> di, </span>
<span id="cb95-28"><a href="9-3-introduction-to-meta-analysis.html#cb95-28"></a>                   <span class="dt">data =</span> metadata)</span>
<span id="cb95-29"><a href="9-3-introduction-to-meta-analysis.html#cb95-29"></a><span class="co"># Perform Meta-analysis</span></span>
<span id="cb95-30"><a href="9-3-introduction-to-meta-analysis.html#cb95-30"></a>result &lt;-<span class="st"> </span><span class="kw">rma</span>(yi, vi, <span class="dt">data =</span> metadata)</span>
<span id="cb95-31"><a href="9-3-introduction-to-meta-analysis.html#cb95-31"></a><span class="co"># Create forest plot. Using ilab and ilab.xpos arguments to add counts</span></span>
<span id="cb95-32"><a href="9-3-introduction-to-meta-analysis.html#cb95-32"></a><span class="kw">forest</span>(result, </span>
<span id="cb95-33"><a href="9-3-introduction-to-meta-analysis.html#cb95-33"></a>       <span class="dt">ilab =</span> <span class="kw">cbind</span>(metadata<span class="op">$</span>ai, metadata<span class="op">$</span>bi, metadata<span class="op">$</span>ci, metadata<span class="op">$</span>di), </span>
<span id="cb95-34"><a href="9-3-introduction-to-meta-analysis.html#cb95-34"></a>       <span class="dt">xlim =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">10</span>, <span class="dv">8</span>), </span>
<span id="cb95-35"><a href="9-3-introduction-to-meta-analysis.html#cb95-35"></a>       <span class="dt">ilab.xpos =</span> <span class="kw">c</span>(<span class="op">-</span><span class="dv">7</span>, <span class="dv">-6</span>, <span class="dv">-5</span>, <span class="dv">-4</span>))</span>
<span id="cb95-36"><a href="9-3-introduction-to-meta-analysis.html#cb95-36"></a><span class="kw">text</span>(<span class="kw">c</span>(<span class="op">-</span><span class="dv">7</span>,<span class="op">-</span><span class="dv">6</span>,<span class="op">-</span><span class="dv">5</span>,<span class="op">-</span><span class="dv">4</span>), <span class="fl">14.7</span>, <span class="kw">c</span>(<span class="st">"E+"</span>, <span class="st">"E-"</span>, <span class="st">"C+"</span>, <span class="st">"C-"</span>), <span class="dt">font =</span> <span class="dv">2</span>, <span class="dt">cex =</span> <span class="fl">.8</span>) <span class="co"># add labels</span></span></code></pre></div>
<p><img src="Statistical_Inferences_files/figure-html/unnamed-chunk-49-1.png" width="672"></p>
<p>The forest plot presents the studies and four columns of data after the study label, which contain the number of successes and failures in the experimental groups (E+ and E-), and the number of successes and failures in the control group (C+ and C-). Imagine we study the percentage of people who get a job
within 6 months after a job training program, compared to a control condition. In Study 1, which had 50 participants in each condition, 29 people in the job training condition got a job within 6 months, and 21 did not get a job. In the control condition, 23 people got a job, but 27 did not. The effect size estimate for the random effects model is 0.65. Feel free to play around with the script, adjusting the number of studies, or the sample sizes in each study, to examine the effect it has on the meta-analytic effect size estimate.</p>
<p>We can also get the meta-analytic test results by printing the test output. We see that there was no heterogeneity in this meta-analysis. This is true (we simulated identical studies) but also highly unlikely to ever happen in real life, where variation in effect sizes between studies included in a meta-analysis is a much more realistic scenario.</p>
<div class="sourceCode" id="cb96"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb96-1"><a href="9-3-introduction-to-meta-analysis.html#cb96-1"></a><span class="co"># Print result meta-analysis</span></span>
<span id="cb96-2"><a href="9-3-introduction-to-meta-analysis.html#cb96-2"></a>result</span></code></pre></div>
<pre><code>## 
## Random-Effects Model (k = 12; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of total heterogeneity): 0 (SE = 0.0645)
## tau (square root of estimated tau^2 value):      0
## I^2 (total heterogeneity / total variability):   0.00%
## H^2 (total variability / sampling variability):  1.00
## 
## Test for Heterogeneity:
## Q(df = 11) = 4.8886, p-val = 0.9364
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   0.6548  0.1132  5.7824  &lt;.0001  0.4328  0.8767  *** 
## 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
</div>
<div id="heterogeneity" class="section level3">
<h3>
<span class="header-section-number">9.3.5</span> Heterogeneity</h3>
<p>Although researchers often primarily use meta-analysis to compute a meta-analytic effect size estimate, and test whether this effect is statistically different from zero, <strong>an arguably much more important use of meta-analyses is to explain variation between (sets of) studies</strong>. This variation among (sets of) studies is referred to as <strong>heterogeneity</strong>. One goal of meta-analyses is not just to code effect sizes and estimate the meta-analytic effect size, but to code factors in studies that can explain heterogeneity, and examine which of these factors account for heterogeneity. This can help in theory evaluation or theory development. Tests have been developed to examine whether the studies included in a meta-analysis vary more than would be expected if the underlying true effect size in all
studies was the same, and measures have been developed to quantify this variation.</p>
<p>If all studies have the same true population effect size, the only source of variation is random error. If there are real differences between (sets of) studies, there are two sources of variation, namely random variation from study to study, <em>and</em> real differences in effect sizes in (sets of) studies.</p>
<p>A classical measure of heterogeneity is Cochran’s Q statistic, which is the weighted sum of the squared differences between effect size estimates in each study, and the meta-analytic effect size estimate. The Q statistic can be used to test whether the absence of heterogeneity can be statistically rejected (by comparing it to the expected amount of variation, which is the degrees of freedom, <em>df</em>, or the number of studies -1, see Borenstein et al., 2009), but it can have low power if the number of studies in the meta-analysis is small <span class="citation">(Huedo-Medina et al., <label for="tufte-mn-76" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-76" class="margin-toggle">2006<span class="marginnote">Huedo-Medina, T. B., Sánchez-Meca, J., Marín-Martínez, F., &amp; Botella, J. (2006). Assessing heterogeneity in meta-analysis: Q statistic or I$2̂$ index? <em>Psychological Methods</em>, <em>11</em>(2), 193.</span>)</span>.</p>
<p>On theoretical grounds one might argue that some heterogeneity will always happen in a meta-analysis, and therefore it is more interesting to quantify the extent to which there is heterogeneity. The I² index measures the extent of true heterogeneity. It is calculated as follows: <span class="math display">\[I^{2} = \ \frac{(Q - k - 1)}{Q} \times 100\%\]</span>, where the k is the number of studies (and k-1 is the degrees of freedom). I² ranges from 0 to 100 and can be interpreted as the percentage of the total variability in a set of effect sizes that is due to heterogeneity. When I² = 0 all variability in the effect size estimates can be explained by within-study error, and when I² = 50 half of the total variability can be explained by true heterogeneity. I² values of 25%, 50%, and 75% can be interpreted as low, medium, and high heterogeneity.</p>
<p>The script below simulates a similar meta-analysis to the example for dichotomous outcomes above, but with a small variation. The first half of the simulated experiments are based on the population success
rates 0.7 and 0.2, but the second half of the simulated experiments are based on the population success rates 0.9 and 0.7. Thus, in this set of studies the odds ratio differs for the first half of the studies, compared to the second half (successes in Group 1 and 2 are set to 0.2 and 0.7 for the first half, but to 0.7 and 0.9 in the second half). There is true heterogeneity. We use the <code>confint</code> function in the metafor package to report both the I² statistic, and its confidence interval.</p>
<div class="sourceCode" id="cb98"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb98-1"><a href="9-3-introduction-to-meta-analysis.html#cb98-1"></a><span class="kw">library</span>(metafor)</span>
<span id="cb98-2"><a href="9-3-introduction-to-meta-analysis.html#cb98-2"></a><span class="kw">set.seed</span>(<span class="dv">2942</span>)</span>
<span id="cb98-3"><a href="9-3-introduction-to-meta-analysis.html#cb98-3"></a>nSims &lt;-<span class="st"> </span><span class="dv">12</span> <span class="co"># Number of simulated experiments</span></span>
<span id="cb98-4"><a href="9-3-introduction-to-meta-analysis.html#cb98-4"></a></span>
<span id="cb98-5"><a href="9-3-introduction-to-meta-analysis.html#cb98-5"></a>pop.pr1 &lt;-<span class="st"> </span><span class="fl">0.7</span> <span class="co"># Set percentage of successes in Group 1</span></span>
<span id="cb98-6"><a href="9-3-introduction-to-meta-analysis.html#cb98-6"></a>pop.pr2 &lt;-<span class="st"> </span><span class="fl">0.2</span> <span class="co"># Set percentage of successes in Group 2</span></span>
<span id="cb98-7"><a href="9-3-introduction-to-meta-analysis.html#cb98-7"></a></span>
<span id="cb98-8"><a href="9-3-introduction-to-meta-analysis.html#cb98-8"></a>ai &lt;-<span class="st"> </span><span class="kw">numeric</span>(nSims) <span class="co"># set up empty vector for successes group 1</span></span>
<span id="cb98-9"><a href="9-3-introduction-to-meta-analysis.html#cb98-9"></a>bi &lt;-<span class="st"> </span><span class="kw">numeric</span>(nSims) <span class="co"># set up empty vector for failures group 1</span></span>
<span id="cb98-10"><a href="9-3-introduction-to-meta-analysis.html#cb98-10"></a>ci &lt;-<span class="st"> </span><span class="kw">numeric</span>(nSims) <span class="co"># set up empty vector for successes group 2</span></span>
<span id="cb98-11"><a href="9-3-introduction-to-meta-analysis.html#cb98-11"></a>di &lt;-<span class="st"> </span><span class="kw">numeric</span>(nSims) <span class="co"># set up empty vector for failures group 2</span></span>
<span id="cb98-12"><a href="9-3-introduction-to-meta-analysis.html#cb98-12"></a></span>
<span id="cb98-13"><a href="9-3-introduction-to-meta-analysis.html#cb98-13"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nSims<span class="op">/</span><span class="dv">2</span>) { <span class="co"># for half (/2) of the simulated studies</span></span>
<span id="cb98-14"><a href="9-3-introduction-to-meta-analysis.html#cb98-14"></a>  n &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">30</span><span class="op">:</span><span class="dv">80</span>, <span class="dv">1</span>)</span>
<span id="cb98-15"><a href="9-3-introduction-to-meta-analysis.html#cb98-15"></a>  x &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, pop.pr1) <span class="co"># produce simulated participants (1 = success, 0 is failure)</span></span>
<span id="cb98-16"><a href="9-3-introduction-to-meta-analysis.html#cb98-16"></a>  y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, pop.pr2) <span class="co"># produce simulated participants (1 = success, 0 is failure)</span></span>
<span id="cb98-17"><a href="9-3-introduction-to-meta-analysis.html#cb98-17"></a>  ai[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(x <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="co"># Successes Group 1</span></span>
<span id="cb98-18"><a href="9-3-introduction-to-meta-analysis.html#cb98-18"></a>  bi[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(x <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="co"># Failures Group 1</span></span>
<span id="cb98-19"><a href="9-3-introduction-to-meta-analysis.html#cb98-19"></a>  ci[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(y <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="co"># Successes Group 2</span></span>
<span id="cb98-20"><a href="9-3-introduction-to-meta-analysis.html#cb98-20"></a>  di[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(y <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="co"># Failures Group 2</span></span>
<span id="cb98-21"><a href="9-3-introduction-to-meta-analysis.html#cb98-21"></a>}</span>
<span id="cb98-22"><a href="9-3-introduction-to-meta-analysis.html#cb98-22"></a></span>
<span id="cb98-23"><a href="9-3-introduction-to-meta-analysis.html#cb98-23"></a>pop.pr1 &lt;-<span class="st"> </span><span class="fl">0.9</span> <span class="co">#Set percentage of successes in Group 1</span></span>
<span id="cb98-24"><a href="9-3-introduction-to-meta-analysis.html#cb98-24"></a>pop.pr2 &lt;-<span class="st"> </span><span class="fl">0.7</span> <span class="co">#Set percentage of successes in Group 2</span></span>
<span id="cb98-25"><a href="9-3-introduction-to-meta-analysis.html#cb98-25"></a></span>
<span id="cb98-26"><a href="9-3-introduction-to-meta-analysis.html#cb98-26"></a><span class="cf">for</span> (i <span class="cf">in</span> (nSims<span class="op">/</span><span class="dv">2</span> <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">:</span>(nSims)) { <span class="co">#for the other half (/2) of each simulated study</span></span>
<span id="cb98-27"><a href="9-3-introduction-to-meta-analysis.html#cb98-27"></a>  n &lt;-<span class="st"> </span><span class="kw">sample</span>(<span class="dv">30</span><span class="op">:</span><span class="dv">80</span>, <span class="dv">1</span>)</span>
<span id="cb98-28"><a href="9-3-introduction-to-meta-analysis.html#cb98-28"></a>  x &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, pop.pr1) <span class="co"># produce simulated participants (1 = success, 0 is failure)</span></span>
<span id="cb98-29"><a href="9-3-introduction-to-meta-analysis.html#cb98-29"></a>  y &lt;-<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, pop.pr2) <span class="co"># produce simulated participants (1 = success, 0 is failure)</span></span>
<span id="cb98-30"><a href="9-3-introduction-to-meta-analysis.html#cb98-30"></a>  ai[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(x <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="co"># Successes Group 1</span></span>
<span id="cb98-31"><a href="9-3-introduction-to-meta-analysis.html#cb98-31"></a>  bi[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(x <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="co"># Failures Group 1</span></span>
<span id="cb98-32"><a href="9-3-introduction-to-meta-analysis.html#cb98-32"></a>  ci[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(y <span class="op">==</span><span class="st"> </span><span class="dv">1</span>) <span class="co"># Successes Group 2</span></span>
<span id="cb98-33"><a href="9-3-introduction-to-meta-analysis.html#cb98-33"></a>  di[i] &lt;-<span class="st"> </span><span class="kw">sum</span>(y <span class="op">==</span><span class="st"> </span><span class="dv">0</span>) <span class="co"># Failures Group 2</span></span>
<span id="cb98-34"><a href="9-3-introduction-to-meta-analysis.html#cb98-34"></a>}</span>
<span id="cb98-35"><a href="9-3-introduction-to-meta-analysis.html#cb98-35"></a></span>
<span id="cb98-36"><a href="9-3-introduction-to-meta-analysis.html#cb98-36"></a><span class="co"># Combine data into dataframe</span></span>
<span id="cb98-37"><a href="9-3-introduction-to-meta-analysis.html#cb98-37"></a>metadata &lt;-<span class="st"> </span><span class="kw">cbind</span>(ai, bi, ci, di)</span>
<span id="cb98-38"><a href="9-3-introduction-to-meta-analysis.html#cb98-38"></a><span class="co"># Create escalc object from metadata dataframe </span></span>
<span id="cb98-39"><a href="9-3-introduction-to-meta-analysis.html#cb98-39"></a>metadata &lt;-<span class="st"> </span><span class="kw">escalc</span>(<span class="dt">measure =</span> <span class="st">"OR"</span>, </span>
<span id="cb98-40"><a href="9-3-introduction-to-meta-analysis.html#cb98-40"></a>                   <span class="dt">ai =</span> ai, <span class="dt">bi =</span> bi, <span class="dt">ci =</span> ci, <span class="dt">di =</span> di, </span>
<span id="cb98-41"><a href="9-3-introduction-to-meta-analysis.html#cb98-41"></a>                   <span class="dt">data =</span> metadata)</span>
<span id="cb98-42"><a href="9-3-introduction-to-meta-analysis.html#cb98-42"></a><span class="co"># Perform Meta-analysis</span></span>
<span id="cb98-43"><a href="9-3-introduction-to-meta-analysis.html#cb98-43"></a>result &lt;-<span class="st"> </span><span class="kw">rma</span>(yi, vi, <span class="dt">data =</span> metadata)</span>
<span id="cb98-44"><a href="9-3-introduction-to-meta-analysis.html#cb98-44"></a><span class="co"># Print result meta-analysis</span></span>
<span id="cb98-45"><a href="9-3-introduction-to-meta-analysis.html#cb98-45"></a>result</span></code></pre></div>
<pre><code>## 
## Random-Effects Model (k = 12; tau^2 estimator: REML)
## 
## tau^2 (estimated amount of total heterogeneity): 0.3174 (SE = 0.2429)
## tau (square root of estimated tau^2 value):      0.5634
## I^2 (total heterogeneity / total variability):   56.53%
## H^2 (total variability / sampling variability):  2.30
## 
## Test for Heterogeneity:
## Q(df = 11) = 25.7650, p-val = 0.0070
## 
## Model Results:
## 
## estimate      se    zval    pval   ci.lb   ci.ub 
##   1.8125  0.2190  8.2764  &lt;.0001  1.3833  2.2417  *** 
## 
## ---
## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</code></pre>
<div class="sourceCode" id="cb100"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb100-1"><a href="9-3-introduction-to-meta-analysis.html#cb100-1"></a><span class="kw">confint</span>(result) <span class="co"># Get confidence interval for indices of heterogeneity</span></span></code></pre></div>
<pre><code>## 
##        estimate   ci.lb   ci.ub 
## tau^2    0.3174  0.0355  1.2286 
## tau      0.5634  0.1883  1.1084 
## I^2(%)  56.5308 12.6888 83.4276 
## H^2      2.3005  1.1453  6.0341</code></pre>
<p>Based on the test for heterogeneity, we can reject the null hypothesis that there is no heterogeneity in the meta-analysis. Tests for heterogeneity themselves have Type 1 and Type 2 error rates, and with a small number of studies (such as in our example, n = 12) tests for heterogeneity can have low power. If you remove the set.seed command and run the code multiple times, you will see that the test for heterogeneity will often not be significant, even though there is true heterogeneity in the simulation. In large meta-analyses, power can be so high that the test always yields a <em>p</em>-value small enough to reject the null hypothesis, but then it is important to look at the I² estimate.</p>
</div>
<div id="metareporting" class="section level3">
<h3>
<span class="header-section-number">9.3.6</span> Improving the reproducibility of meta-analyses</h3>
<p>Although meta-analyses do not provide definitive conclusions, they are typically interpreted as state-of-the-art empirical knowledge about a specific effect or research area. Large-scale meta-analyses often accumulate a massive number of citations and influence future research and theory development. It is therefore essential that published meta-analyses are of the highest possible quality.</p>
<p>At the same time, the conclusions from meta-analyses are often open for debate and are subject to change as new data becomes available. We recently proposed practical recommendations to increase the reproducibility of meta-analyses to facilitate quality control, improve reporting guidelines, allow researchers to re-analyze meta-analyses based on alternative inclusion criteria, and future-proof meta-analyses by making sure the collected meta-analytic data is shared so that continuously accumulating meta-analyses can be performed, and so that novel statistical techniques can be applied on the collected data as they become available <span class="citation">(Lakens et al., <label for="tufte-mn-77" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-77" class="margin-toggle">2016<span class="marginnote">Lakens, D., Hilgard, J., &amp; Staaks, J. (2016). On the reproducibility of meta-analyses: Six practical recommendations. <em>BMC Psychology</em>, <em>4</em>, 24. <a href="https://doi.org/10.1186/s40359-016-0126-3">https://doi.org/10.1186/s40359-016-0126-3</a></span>)</span>. The need for the improvement in reproducibility of meta-analysis is clear - a recent review of 150 meta-analyses in Psychological BUlletin revealed that only 1 meta-analysis shared the statistical code <span class="citation">(Polanin et al., <label for="tufte-mn-78" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-78" class="margin-toggle">2020<span class="marginnote">Polanin, J. R., Hennessy, E. A., &amp; Tsuji, S. (2020). Transparency and Reproducibility of Meta-Analyses in Psychology: A Meta-Review. <em>Perspectives on Psychological Science</em>, <em>15</em>(4), 1026–1041. <a href="https://doi.org/10.1177/1745691620906416">https://doi.org/10.1177/1745691620906416</a></span>)</span>. This is unacceptable in the current day and age. Following the recommendations summarized in Table <a href="9-3-introduction-to-meta-analysis.html#tab:table-rec1">9.1</a> should substantially improve the state-of-the-art in meta-analyses.</p>
<p><!--
<caption>--><span class="marginnote shownote"><span id="tab:table-rec1">Table 9.1: </span>Six practical recommendations to improve the quality and reproducibility of meta-analyses.</span><!--</caption>--></p>
<table>
<thead><tr>
<th style="text-align:left;">
What?
</th>
<th style="text-align:left;">
How?
</th>
</tr></thead>
<tbody>
<tr>
<td style="text-align:left;">
Facilitate cumulative science
</td>
<td style="text-align:left;">
Disclose all meta-analytic data (effect sizes, sample sizes for each condition, test statistics and degrees of freedom, means, standard deviations, and correlations between dependent observations) for each data point. Quote relevant text from studies that describe the meta-analytic data to prevent confusion, such as when one effect size is selected from a large number of tests reported in a study. When analyzing subgroups, include quotes from the original study that underlie this classification, and specify any subjective decisions.
</td>
</tr>
<tr>
<td style="text-align:left;">
Facilitate quality control
</td>
<td style="text-align:left;">
Specify which effect size calculations are used and which assumptions are made for missing data (e.g., assuming equal sample sizes in each condition, imputed values for unreported effect sizes), if necessary for each effect size extracted from the literature. Specify who extracted and coded the data, knowing it is preferable that two researchers independently extract effect sizes from the literature.
</td>
</tr>
<tr>
<td style="text-align:left;">
Use reporting guidelines
</td>
<td style="text-align:left;">
A minimal requirement when reporting meta-analyses is to adhere to one of the reporting standards (e.g., PRISMA). The reporting guidelines ask authors of meta-analyses to report essential information that should be made available either in the main text of the article, or by providing a completed checklist as supplementary material during review and after publication.
</td>
</tr>
<tr>
<td style="text-align:left;">
Preregister
</td>
<td style="text-align:left;">
Whenever possible, pre-register the meta-analysis research protocol to distinguish between confirmatory and exploratory analyses. Perform a prospective meta-analysis where possible.
</td>
</tr>
<tr>
<td style="text-align:left;">
Facilitate reproducibility
</td>
<td style="text-align:left;">
Allow others to re-analyze the data to examine how sensitive the results are to subjective choices such as inclusion criteria. Always include a link to data files that can be directly analyzed with statistical software, either by providing completely reproducible scripts containing both the data and the reported analyses in free software (e.g., R), or at the very minimum a spreadsheet that contains all meta-analytic data that can easily analyzed in any statistical program.
</td>
</tr>
<tr>
<td style="text-align:left;">
Recruit expertise
</td>
<td style="text-align:left;">
Consider consulting a librarian before you start the literature search, and a statistician before coding the effect sizes, for advice on how make the literature search and effect size calculations reproducible.
</td>
</tr>
</tbody>
</table>
</div>
</div>
<!-- </div> -->
</body></html>

<p style="text-align: center;">
<a href="9-2-mixed.html"><button class="btn btn-default">Previous</button></a>
<a href="10-bias.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-08-15
</p>
</div>
</div>



</body>
</html>
