<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 4 33% (or any other) power curve | Improving Your Statistical Inferences</title>
<meta name="author" content="Daniel Lakens">
<meta name="description" content='lines(x=seq(0, p.crit-.01, by=.01)+.005, y=theoretical_power_curve(power, p.max=p.crit)*100, col="darkgreen", lty="dashed", lwd=2) text(x=seq(0, p.crit-.01, by=.01)+.006, y=perc + 8, col="black",...'>
<meta name="generator" content="bookdown 0.24 with bs4_book()">
<meta property="og:title" content="Chapter 4 33% (or any other) power curve | Improving Your Statistical Inferences">
<meta property="og:type" content="book">
<meta property="og:description" content='lines(x=seq(0, p.crit-.01, by=.01)+.005, y=theoretical_power_curve(power, p.max=p.crit)*100, col="darkgreen", lty="dashed", lwd=2) text(x=seq(0, p.crit-.01, by=.01)+.006, y=perc + 8, col="black",...'>
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 4 33% (or any other) power curve | Improving Your Statistical Inferences">
<meta name="twitter:description" content='lines(x=seq(0, p.crit-.01, by=.01)+.005, y=theoretical_power_curve(power, p.max=p.crit)*100, col="darkgreen", lty="dashed", lwd=2) text(x=seq(0, p.crit-.01, by=.01)+.006, y=perc + 8, col="black",...'>
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/header-attrs-2.11/header-attrs.js"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.3.1/transition.js"></script><script src="libs/bs3compat-0.3.1/tabs.js"></script><script src="libs/bs3compat-0.3.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="libs/kePrint-0.0.1/kePrint.js"></script><link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet">
<script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><link rel="stylesheet" href="bs4_style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Improving Your Statistical Inferences</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Welcome</a></li>
<li><a class="" href="pvalue.html"><span class="header-section-number">1</span> Using p-values to test a hypothesis</a></li>
<li><a class="" href="errorcontrol.html"><span class="header-section-number">2</span> Error control</a></li>
<li><a class="" href="empirical-p-curve.html"><span class="header-section-number">3</span> empirical p-curve</a></li>
<li><a class="active" href="or-any-other-power-curve.html"><span class="header-section-number">4</span> 33% (or any other) power curve</a></li>
<li><a class="" href="references.html"><span class="header-section-number">5</span> References</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/Lakens/statistical_inferences">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="or-any-other-power-curve" class="section level1" number="4">
<h1>
<span class="header-section-number">4</span> 33% (or any other) power curve<a class="anchor" aria-label="anchor" href="#or-any-other-power-curve"><i class="fas fa-link"></i></a>
</h1>
<p>lines(x=seq(0, p.crit-.01, by=.01)+.005, y=theoretical_power_curve(power, p.max=p.crit)*100, col="darkgreen", lty="dashed", lwd=2)</p>
<p>text(x=seq(0, p.crit-.01, by=.01)+.006, y=perc + 8, col="black", label=paste0(round(perc), "%"), cex=)</p>
<p>legend("topleft", legend=c(paste0("Test for right skewness: p = ", round(p_curve_3(pps = res)<span class="math inline">\(p_evidence,2)), paste0("Test for flatness: p = ", round(p_curve_3(pps = res)\)</span>p_lack,2))), bty="n")</p>
<pre><code>
&lt;img src="13-bias_files/figure-html/unnamed-chunk-2-1.png" width="100%" style="display: block; margin: auto;" /&gt;

The output will in the p-curve app will look similar to the figure above. The *p*-curve analysis shows that there is no evidential value in the set of studies (the curve is not right-skewed, as we would expect if there is a true effect and decent power to detect such an effect), and the *p*-value distribution is flatter than we would expect if we have 33% power, so the curve lacks evidential value.  

Based on the continuous Stoufferâ€™s test for the full *p*-curve, we can conclude the observed *p*-value distribution is not skewed enough to be interpreted as the presence of a true effect size, and it is flatter than we would expect if the studies had 33% power. **Therefore, we can conclude these studies do not provide support for the theory that generated these studies**. The theory might still be true - but the set of studies we have analyzed here do not provide support for the theory.

### Z-curve analysis

GRAB EXAMPLE FROM SCIENCEVERSE. 

For recent examples, see [@sotola_garbage_2022]. 

A relatively novel technique is *z*-curve, which is basically a meta-analysis of observed power (Bartos &amp; Schimmack, 2020; Schimmack &amp; Brunner, 2020). This analysis can be used to examine selection bias in the literature. Scientists often selectively report only statistically significant results in their manuscript, and fail to report non-significant tests they have performed. This selection for significant results introduces bias in the scientific literature. 

Like a traditional meta-analysis, *z*-curve transforms observed test results (*p*-values) into *z*-scores. Using mixtures of normal distributions centered at means 0 to 6, *z*-curve aims to estimate the average power of the studies. The newest version of *z*-curve then calculates the *observed discovery rate* (the percentage of significant results, or the observed power), the *expected discovery rate* (EDR: the proportion of the area under the curve on the right side of the significance criterion) and the expected replication rate (ERR: the proportion of successfully replicated significant studies from all significant studies). *Z*-curve is able to correct for selection bias for positive results (under specific assumptions), and can estimate the EDR and ERR using only the significant *p*-values.

To examine the presence of bias, it is preferable to submit non-significant and significant *p*-values to a *z*-curve analysis, even if only the significant *p*-values are used to produce estimates. Publication bias can then be examined by comparing the ODR to the EDR. If the results of studies are shared in a well-structured meta-study file, all the *p*-values needed to perform a *z*-curve analysis are directly available, and it is clear which statistical test is related to a hypothesis is researchers are interested in including only specific analyses in the *z*-curve.

Since our simulated studies have bias, the *z*-curve analysis should be able to indicate this. 


```r
# devtools::install_github("FBartos/zcurve")
# Get the p-value for each analysis
p_vals &lt;- metadata$pvalues
z &lt;- qnorm(1-p_vals/2)
# Perform the z-curve analysis using the z-curve package
z_res &lt;- zcurve::zcurve(z, method = "EM", bootstrap = 1000)
plot(z_res, annotation = TRUE, CI = TRUE)</code></pre>
<div class="inline-figure"><img src="13-bias_files/figure-html/unnamed-chunk-3-1.png" width="100%" style="display: block; margin: auto;"></div>
<div class="sourceCode" id="cb12"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/print.html">print</a></span><span class="op">(</span><span class="va">z_res</span><span class="op">)</span></code></pre></div>
<pre><code>## Call:
## zcurve::zcurve(z = z, method = "EM", bootstrap = 1000)
## 
## Estimates:
##        ERR        EDR 
## 0.04247541 0.05470193</code></pre>
<div class="sourceCode" id="cb14"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span class="fu"><a href="https://rdrr.io/r/base/summary.html">summary</a></span><span class="op">(</span><span class="va">z_res</span>, all <span class="op">=</span> <span class="cn">TRUE</span><span class="op">)</span></code></pre></div>
<pre><code>## Call:
## zcurve::zcurve(z = z, method = "EM", bootstrap = 1000)
## 
## model: EM via EM
## 
##               Estimate  l.CI   u.CI
## ERR              0.042 0.025  0.147
## EDR              0.055 0.050  0.142
## Soric FDR        0.910 0.319  1.000
## File Drawer R   17.281 6.062 19.000
## Expected N        1828   706   2000
## Missing N         1728   606   1900
## 
## Model converged in 18 + 113 iterations
## Fitted using 100 z-values. 100 supplied, 100 significant (ODR = 1.00, 95% CI [0.95, 1.00]).
## Q = -7.69, 95% CI[-22.84, 8.62]</code></pre>
<p>We see that out of 100 studies were significant, which makes the observed power (across all these studies with different sample sizes) 100% (95% CI[0.95;1]). The expected discovery rate (EDR) is only 5%, which differs statistically differ from the observed discovery rate, which means there is clear indication of selection bias based on the <em>z</em>-curve analysis. The expected replicability rate for these studies is 6% 95% CI[0.05;0.06] which is in line with the expectation that we will only observe 5% Type 1 errors. Thus, even though we only entered significant <em>p</em>-values, Z-curve analysis correctly suggests that we should not expect these results to replicate.</p>
<div id="conclusion" class="section level3" number="4.0.1">
<h3>
<span class="header-section-number">4.0.1</span> Conclusion<a class="anchor" aria-label="anchor" href="#conclusion"><i class="fas fa-link"></i></a>
</h3>
<p>Publication bias is a big problem in science. It is present in almost all meta-analyses performed on the primary hypothesis test in scientific articles, because these articles are much more likely to be submitted and accepted for publication if this test is statistically significant. Meta-analytic effect size estimates that are not corrected for bias will almost always overestimate the true effect size. Publication bias inflates the effect size estimate to an unknown extent â€“ but it could even be the case that the true effect size is zero!</p>
<p>There is a lot of activity in the literature on tests for publication bias. There are many different tests, and you need to carefully check the assumptions of each test before applying it. Most tests donâ€™t work well when there is large heterogeneity, and heterogeneity is quite likely. Iâ€™d currently recommend applying multiple tests that should, based on the literature, give informative results based on the studies in your meta-analysis. When you plan to perform a meta-analysis, you should always examine whether there is publication bias. Given that bias detection tests is an active field, read up on the latest work in this area. None of the bias detection techniques discussed in this assignment will be a silver bullet, but they will be better than naively interpreting the uncorrected effect size estimate from the meta-analysis.</p>

</div>
</div>
  <div class="chapter-nav">
<div class="prev"><a href="empirical-p-curve.html"><span class="header-section-number">3</span> empirical p-curve</a></div>
<div class="next"><a href="references.html"><span class="header-section-number">5</span> References</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li>
<a class="nav-link" href="#or-any-other-power-curve"><span class="header-section-number">4</span> 33% (or any other) power curve</a><ul class="nav navbar-nav"><li><a class="nav-link" href="#conclusion"><span class="header-section-number">4.0.1</span> Conclusion</a></li></ul>
</li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/Lakens/statistical_inferences/blob/master/13-bias.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/Lakens/statistical_inferences/edit/master/13-bias.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Improving Your Statistical Inferences</strong>" was written by Daniel Lakens. It was last built on 2022-03-15.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>
