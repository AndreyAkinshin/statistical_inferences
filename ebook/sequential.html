<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="14 Sequential Analysis | Improving Your Statistical Inferences" />
<meta property="og:type" content="book" />
<meta property="og:url" content="http://themethodsection.com/ebook/" />
<meta property="og:image" content="http://themethodsection.com/ebook/images/cover.jpg" />
<meta property="og:description" content="Online textbook to Improve Your Statistical Inferences" />


<meta name="author" content="Daniel Lakens" />

<meta name="date" content="2020-08-07" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Online textbook to Improve Your Statistical Inferences">

<title>14 Sequential Analysis | Improving Your Statistical Inferences</title>

<link href="libs/tufte-css-2015.12.29/tufte.css" rel="stylesheet" />
<link href="libs/tufte-css-2015.12.29/envisioned.css" rel="stylesheet" />
<link href="libs/msmb-css-0/msmb.css" rel="stylesheet" />
<script>
function toggle_visibility(id1, id2) {
var e = document.getElementById(id1);
var f = document.getElementById(id2);

e.style.display = ((e.style.display!='none') ? 'none' : 'block');

if(f.classList.contains('fa-plus-square')) {
    f.classList.add('fa-minus-square')
    f.classList.remove('fa-plus-square')
} else {
    f.classList.add('fa-plus-square')
    f.classList.remove('fa-minus-square')
}

}
</script>
<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }

code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
<link rel="stylesheet" href="center.css" type="text/css" />
<link rel="stylesheet" href="custom-msmbstyle.css" type="text/css" />

</head>

<body>



<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul class="navbar">
<li class="msmb"><p class="title">Improving Your Statistical Inferences<p><p class="author">Daniel Lakens</p>
<li class="dropdown" style="float:right">
<a href="javascript:void(0)" class="dropbtn">&#x25BE; Chapters</a>
<div class="dropdown-content">
<a href="index.html">Welcome</a>
<a href="contents.html">Contents</a>
<a href="preface.html">Preface</a>
<a href="introduction.html">Introduction</a>
<a href="pvalue.html"><span class="toc-section-number">1</span> What is a <em>p</em>-value</a>
<a href="power.html"><span class="toc-section-number">2</span> Sample size justification</a>
<a href="questions.html"><span class="toc-section-number">3</span> Asking Statistical Questions</a>
<a href="errorcontrol.html"><span class="toc-section-number">4</span> Error Control</a>
<a href="effectsizesCI.html"><span class="toc-section-number">5</span> Effect Sizes and Confidence Intervals</a>
<a href="equivalencetest.html"><span class="toc-section-number">6</span> Equivalence Testing</a>
<a href="severity.html"><span class="toc-section-number">7</span> Severe Tests and Risky Predictions</a>
<a href="sesoi.html"><span class="toc-section-number">8</span> Smallest Effect Size of Interest</a>
<a href="meta.html"><span class="toc-section-number">9</span> Meta-analysis</a>
<a href="bias.html"><span class="toc-section-number">10</span> Bias detection</a>
<a href="computationalreproducibility.html"><span class="toc-section-number">11</span> Computational Reproducibility</a>
<a href="prereg.html"><span class="toc-section-number">12</span> Preregistration and Transparency</a>
<a href="bayes.html"><span class="toc-section-number">13</span> Bayesian statistics</a>
<a id="active-page" href="sequential.html"><span class="toc-section-number">14</span> Sequential Analysis</a><ul class="toc-sections">
<li class="toc"><a href="#NA"> Choosing alpha levels for sequential analyses.</a></li>
<li class="toc"><a href="#comparing-spending-functions"> Comparing Spending Functions</a></li>
<li class="toc"><a href="#sample-size-for-sequential-designs"> Sample Size for Sequential Designs</a></li>
<li class="toc"><a href="#test-for-non-inferiority"> Test for non-inferiority</a></li>
<li class="toc"><a href="#stopping-for-futility"> Stopping for futility</a></li>
<li class="toc"><a href="#conditional-power"> Conditional power</a></li>
</ul>
<a href="references.html"><span class="toc-section-number">15</span> References</a>
</div>
</li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN" "http://www.w3.org/TR/REC-html40/loose.dtd">
<html><body><div id="sequential" class="section level1">
<h1>
<span class="header-section-number">14</span> Sequential Analysis</h1>
<p>Imagine you design a study, determine the sample size you will collect based on an a-priori power analysis with a desired 80% power, have collected data, analyzed the results, and you find a <em>p</em>-value for your primary hypothesis of <em>p</em> = 0.09. You believe this might be a Type 2 error, and you are willing to collect more data to examine your hypothesis. In the past, researchers would often use a practice called <strong>optional stopping</strong> where they would continue the data collection, without adjusting the alpha level for multiple comparisons <span class="citation">(Fiedler &amp; Schwarz, <label for="tufte-mn-84" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-84" class="margin-toggle">2015<span class="marginnote">Fiedler, K., &amp; Schwarz, N. (2015). Questionable Research Practices Revisited. <em>Social Psychological and Personality Science</em>, 1948550615612150. <a href="https://doi.org/10.1177/1948550615612150">https://doi.org/10.1177/1948550615612150</a></span>; John et al., <label for="tufte-mn-85" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-85" class="margin-toggle">2012<span class="marginnote">John, L. K., Loewenstein, G., &amp; Prelec, D. (2012). Measuring the prevalence of questionable research practices with incentives for truth telling. <em>Psychological Science</em>, <em>23</em>(5), 524–532.</span>)</span>. However, this inflates the Type 1 error rate. Luckily, there is a solution to be able to stop the data collection when an effect is significant, and continue up to the maximum sample size you are willing to collect when it is not significant: <strong>sequential analysis</strong>. In sequential analysis a researcher designs a study such that they are able to perform <strong>interim analyses</strong>, say when 25%, 50%, and 75% of the data is collected. At each interim analysis a test is performed at a corrected alpha level, that over all planned analyses maintains the desired Type 1 error rate. For example, each of four analyses might be performed using an alpha level of 0.0091. The analysis at the first interim analysis yields a <em>p</em> = 0.21, data collection would continue. If at the second interim analysis a <em>p</em> = 0.007 is observed, data collection is terminated, and the null hypothesis is rejected. Even though the researcher repeatedly analyses the data, the corrected alpha level guarantees that the Type 1 error rate remains at 5%.</p>
<p>Although the use of sequential analyses is not common, they have a long history. As early as 1929, Dodge and Romig realized that analyzing the data sequentially was more efficient than doing so once <span class="citation">(Dodge &amp; Romig, <label for="tufte-mn-86" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-86" class="margin-toggle">1929<span class="marginnote">Dodge, H. F., &amp; Romig, H. G. (1929). A Method of Sampling Inspection. <em>Bell System Technical Journal</em>, <em>8</em>(4), 613–631. <a href="https://doi.org/10.1002/j.1538-7305.1929.tb01240.x">https://doi.org/10.1002/j.1538-7305.1929.tb01240.x</a></span>)</span>. Wald, who popularized the idea of sequential tests of hypotheses in <span class="citation">(<label for="tufte-mn-87" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-87" class="margin-toggle">1945<span class="marginnote">Wald, A. (1945). Sequential tests of statistical hypotheses. <em>The Annals of Mathematical Statistics</em>, <em>16</em>(2), 117–186.</span>)</span>, performed his work during the second world war. He was only allowed to publish his findings after the war had ended, because as he writes in a historical note:</p>
<blockquote>
<p>Because of the substantial savings in the expected number of observations effected by the sequential probability ratio test, and because of the simplicity of this test procedure in practical applications, the National Defense Research Committee considered these developments sufficiently useful for the war effort to make it desirable to keep the results out of the reach of the enemy, at least for a certain period of time. The author was, therefore, requested to submit his findings in a restricted report which was dated September, 1943.</p>
</blockquote>
<p>In other words, we have a method that so substantially increases the efficiency of hypothesis tests that it would not be shared with the enemy during war time - yet few researchers outside of medicine currently use it! In medicine, efficiency is not just a matter of money, but also of saving lives. If a drug shows it substantially increases the probability that people will survive a disease, it is deemed ethical to terminate a trial early, and administer the treatment to patients enrolled in the control group as well. Sequential analyses are established procedures, and have been developed in great detail over the last decades <span class="citation">(Jennison &amp; Turnbull, <label for="tufte-mn-88" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-88" class="margin-toggle">2000<span class="marginnote">Jennison, C., &amp; Turnbull, B. W. (2000). <em>Group sequential methods with applications to clinical trials</em>. Chapman &amp; Hall/CRC.</span>; Proschan et al., <label for="tufte-mn-89" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-89" class="margin-toggle">2006<span class="marginnote">Proschan, M. A., Lan, K. K. G., &amp; Wittes, J. T. (2006). <em>Statistical monitoring of clinical trials: A unified approach</em>. Springer.</span>; Wassmer &amp; Brannath, <label for="tufte-mn-90" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-90" class="margin-toggle">2016<span class="marginnote">Wassmer, G., &amp; Brannath, W. (2016). <em>Group Sequential and Confirmatory Adaptive Designs in Clinical Trials</em>. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-32562-0">https://doi.org/10.1007/978-3-319-32562-0</a></span>)</span>. Here, we will explain the basics of how to control error rates in sequential analyses, and perform a-priori power analysis and compare when sequential designs will be more or less efficient than fixed designs.</p>
<div id="choosing-alpha-levels-for-sequential-analyses." class="section level2">
<h2>
<span class="header-section-number">14.1</span> Choosing alpha levels for sequential analyses.</h2>
<p>In sequential designs researchers will collect data with the plan to analyze the data at various times during the data collections. For example, a researcher plans to collect data from 200 participants and plans to analyse the data after 100 participants are collected, and once again after 200 participants are collected. Each analyses is called a <strong>look</strong>, so there are in total 2 looks at the data planned, with one interim analysis, and one final analysis. Not all looks have to occur in practice. If the analysis reveals a statistically significant result at look 1, data collection can be terminated. It is also possible to stop the data collection at look 1 because a predicted effect is absent, and continuing the data collection is not deemed worthwhile, which is called <strong>stopping for futility</strong>.</p>
<p>If one would analyze the data at multiple looks without correcting the alpha level, the Type 1 error rate would inflate <span class="citation">(Armitage et al., <label for="tufte-mn-91" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-91" class="margin-toggle">1969<span class="marginnote">Armitage, P., McPherson, C. K., &amp; Rowe, B. C. (1969). Repeated significance tests on accumulating data. <em>Journal of the Royal Statistical Society: Series A (General)</em>, <em>132</em>(2), 235–244.</span>)</span>. As Armitage and colleagues show, with equally spaced looks, the alpha level inflates to 0.142 after 5 looks, 0.374 after 100 looks, and 0.530 after 1000 looks. Looking at the data twice is conceptually similar to deciding if a result is significant if one of two dependent variables shows a statistically significant effect. However, an important difference is that in the case of sequential analyses the multiple tests are not independent, but dependent. A test at look to combines the old data collected at look 1 with the new data at look 2. This means the Type 1 error rate inflates less quickly compared to independent tests, and we will see below this enables more efficient and flexible solutions to controlling error rates.</p>
<p>The solution to control Type 1 error inflation is again conceptually similar to a multiple comparison problem. By lowering the alpha level at each look, the Type 1 error rate can be controlled. They way the alpha level is reduced differs, however. To control the Type 1 error rate, we would lower the alpha level for each test, for example using the Bonferroni procedure where each test would be performed at <span class="math inline">\(\alpha/2\)</span>. In sequential analyses we similarly adjust the alpha level. It is even possible to just use a Bonferroni correction <span class="citation">(Wassmer &amp; Brannath, <label for="tufte-mn-92" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-92" class="margin-toggle">2016<span class="marginnote">Wassmer, G., &amp; Brannath, W. (2016). <em>Group Sequential and Confirmatory Adaptive Designs in Clinical Trials</em>. Springer International Publishing. <a href="https://doi.org/10.1007/978-3-319-32562-0">https://doi.org/10.1007/978-3-319-32562-0</a></span>)</span>. But because the data is dependent (at look 2 we combine the data we collected at look 1 with the new data, so the data covary) the way to correct alpha levels can be done more efficiently. If you combine multiple looks at the data with multiple comparisons, you would first correct the alpha level for multiple looks, and then correct the alpha level at each look for the multiple comparison correction. Because the alpha level is corrected, it does not matter which statistical test you perform at each look, all that matters is that the <em>p</em>-value is compared to the corrected alpha level.</p>
<div id="pocock-correction" class="section level3">
<h3>
<span class="header-section-number">14.1.1</span> Pocock correction</h3>
<p>We will start with the Pocock correction, which is the simplest way to correct the alpha level for multiple looks. Conceptually, it is very similar to the Bonferroni correction. We can see at the <a href="https://en.wikipedia.org/wiki/Pocock_boundary">Wikipedia page for the Pocock correction</a> that with 2 interim analyses the alpha level for each look is 0.0294, for three looks it is 0.0221, for 4 looks it is 0.0182, and for 5 looks it is 0.0158. We see the correction is slightly more efficient than using a Bonferroni correction (in which case the alpha levels would be 0.025, 0.0167, 0.0125, and 0.01). Applying the Pocock procedure requires 1) specifying the number of looks in advance, and 2) equally spaced looks, where each batch of observations has the same size (e.g., looking after 25, 50, 75 and 100 observations).</p>
<p>Note that we can accurately calculate the alpha levels that should be used to 4 digits after the decimal points, but the <a href="http://daniellakens.blogspot.com/2020/01/observed-alpha-levels-why-statistical.html">alpha level you will observe for all tests in your lifetime probably has too much variability</a> to worry too much about anything after 3 digits after the decimal point (and maybe even 2). We will compute alpha levels in this tutorial with higher precision than you need to care about in real life.</p>
<p>We will use multiple packages in R to compute corrected alpha levels for each look, such as <a href="https://cran.r-project.org/web/packages/gsDesign/index.html">gsDesign</a>, <a href="https://cran.r-project.org/web/packages/rpact/index.html">rpact</a>, and <a href="https://cran.r-project.org/web/packages/ldbounds/index.html">ldbounds</a>. RPact is also available as a <a href="https://rpact.shinyapps.io/public/">Shiny app</a>.</p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="sequential.html#cb134-1"></a><span class="co"># Use Rpact to specify a design with 2 looks and Pocock correction</span></span>
<span id="cb134-2"><a href="sequential.html#cb134-2"></a></span>
<span id="cb134-3"><a href="sequential.html#cb134-3"></a>design &lt;-<span class="st"> </span><span class="kw">getDesignGroupSequential</span>(</span>
<span id="cb134-4"><a href="sequential.html#cb134-4"></a>  <span class="dt">kMax =</span> <span class="dv">2</span>,</span>
<span id="cb134-5"><a href="sequential.html#cb134-5"></a>  <span class="dt">typeOfDesign =</span> <span class="st">"P"</span>,</span>
<span id="cb134-6"><a href="sequential.html#cb134-6"></a>  <span class="dt">sided =</span> <span class="dv">2</span>,</span>
<span id="cb134-7"><a href="sequential.html#cb134-7"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span></span>
<span id="cb134-8"><a href="sequential.html#cb134-8"></a>)</span>
<span id="cb134-9"><a href="sequential.html#cb134-9"></a><span class="kw">summary</span>(design)</span></code></pre></div>
<pre><code>## Sequential analysis with a maximum of 2 looks (group sequential design)
## 
## Stage                                   1      2 
## Information rate                      50%   100% 
## Efficacy boundary (z-value scale)   2.178  2.178 
## Cumulative alpha spent             0.0294 0.0500 
## Two-sided local significance level 0.0294 0.0294</code></pre>
<p>Rpact makes it easy to plot the boundaries (based on the critical values) for each look. We see the critical values are higher than the 1.96 we would use for a fixed design with a 5% alpha level, namely: 2.1782721, 2.1782721.</p>
<div class="figure">
<span id="fig:boundplot1"></span>
<p class="caption marginnote shownote">
Figure 14.1: Plot of critical boundaries at each look for a 2 look design with a Pocock correction.
</p>
<img src="Statistical_Inferences_files/figure-html/boundplot1-1.png" alt="Plot of critical boundaries at each look for a 2 look design with a Pocock correction." width="672">
</div>
<p>We can also use the <code>gsDesign</code> package (not that the gsDesign package reports one-sided alpha levels, and thus returns a one-sided alpha level of 0.0147, instead of the two-sided alpha level 0.294. You will need to double the alpha level for a two-sided test (or just use Rpact, which reports two-sided alpha levels when asked).</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="sequential.html#cb136-1"></a>seq_design &lt;-<span class="st"> </span><span class="kw">gsDesign</span>(</span>
<span id="cb136-2"><a href="sequential.html#cb136-2"></a>  <span class="dt">k =</span> <span class="dv">2</span>, <span class="co"># k = number of looks = 2</span></span>
<span id="cb136-3"><a href="sequential.html#cb136-3"></a>  <span class="dt">test.type =</span> <span class="dv">2</span>,</span>
<span id="cb136-4"><a href="sequential.html#cb136-4"></a>  <span class="dt">alpha =</span> <span class="fl">.025</span>, <span class="co"># gsDesign computes one-sided alpha levels, so we halve alpha</span></span>
<span id="cb136-5"><a href="sequential.html#cb136-5"></a>  <span class="dt">sfu =</span> <span class="st">"Pocock"</span></span>
<span id="cb136-6"><a href="sequential.html#cb136-6"></a>)</span>
<span id="cb136-7"><a href="sequential.html#cb136-7"></a></span>
<span id="cb136-8"><a href="sequential.html#cb136-8"></a><span class="kw">gsBoundSummary</span>(seq_design)</span></code></pre></div>
<pre><code>##                Analysis               Value Efficacy Futility
##               IA 1: 50%                   Z   2.1783  -2.1783
##  N/Fixed design N: 0.55         p (1-sided)   0.0147   0.0147
##                             ~delta at bound   0.9061  -0.9061
##                         P(Cross) if delta=0   0.0147   0.0147
##                         P(Cross) if delta=1   0.5893   0.0000
##                   Final                   Z   2.1783  -2.1783
##   N/Fixed design N: 1.1         p (1-sided)   0.0147   0.0147
##                             ~delta at bound   0.6407  -0.6407
##                         P(Cross) if delta=0   0.0250   0.0250
##                         P(Cross) if delta=1   0.9000   0.0000</code></pre>
<p>It is also possible to recreate these analyses in the GroupSeq package, which has a GUI based interface. Run ‘groupseq(mode = “g”)’ in R, and the three screenshots below create the same output.</p>
<div class="figure">
<span id="fig:groupseq1"></span>
<p class="caption marginnote shownote">
Figure 14.2: Screenshot of the GroupSeq GUI to choose a task.
</p>
<img src="images/groupseq1.png" alt="Screenshot of the GroupSeq GUI to choose a task." width="307">
</div>
<div class="figure">
<span id="fig:groupseq2"></span>
<p class="caption marginnote shownote">
Figure 14.3: Screenshot of the GroupSeq GUI to compute bounds.
</p>
<img src="images/groupseq2.png" alt="Screenshot of the GroupSeq GUI to compute bounds." width="364">
</div>
<div class="figure">
<span id="fig:groupseq3"></span>
<p class="caption marginnote shownote">
Figure 14.4: Screenshot of the output of the GroupSeq GUI.
</p>
<img src="images/groupseq3.png" alt="Screenshot of the output of the GroupSeq GUI." width="601">
</div>
<p>The analysis can also be performed in the RPACT <a href="https://rpact.shinyapps.io/public/">shiny app</a> which also allows users to create all plots through simple menu options, and download a complete report of the analyses (e.g., for a preregistration document). The RPACT shiny app is the easiest resource to use from all options discussed here.</p>
<div class="figure">
<span id="fig:rpactshiny"></span>
<p class="caption marginnote shownote">
Figure 14.5: Screenshot of rpact Shiny app.
</p>
<img src="images/rpact1.png" alt="Screenshot of rpact Shiny app." width="600">
</div>
</div>
</div>
<div id="comparing-spending-functions" class="section level2">
<h2>
<span class="header-section-number">14.2</span> Comparing Spending Functions</h2>
<p>It can be useful to explicitly compare different types of designs. As explained before, the Pocock correction maintains a fixed alpha level at each look. The O’Brien-Fleming correction uses a higher threshold for early looks, but has the advantage that the final look occurs closer to the uncorrected alpha level. Because the alpha level is very similar at the last look, so is the total required sample size. Lowering the alpha level means the sample size needs to be increased to maintain the same desired level of statistical power, so different spending functions also require a different increase in the final sample size (to compensate for the lower alpha level, while maintaining the same statistical power). Sequential designs always need to be planned for a slightly larger total sample size at the final look, although as we will see below, because we can expect to stop at earlier looks, on average sample size will be smaller when using sequential designs compared to fixed designs.</p>
<div class="figure">
<span id="fig:spending-comparison"></span>
<p class="caption marginnote shownote">
Figure 14.6: Comparison of the Pocock and O’Brien-Fleming boundaries.
</p>
<img src="Statistical_Inferences_files/figure-html/spending-comparison-1.png" alt="Comparison of the Pocock and O'Brien-Fleming boundaries." width="672">
</div>
<p>We see that at each of the 5 looks the critical value for our test is higher than 1.96 (the critical value without correcting for multiple looks, assuming a normal distribution, indicated by the black dashed line). The Pocock correction (P, blue line) has the same critical value at each look: 2.4131803, 2.4131803, 2.4131803, 2.4131803, 2.4131803, while the critical values decrease for each look with the O’Brien-Fleming correction (OF, red line): 4.5617423, 3.2256389, 2.6337232, 2.2808712, 2.0400732. The first three looks use an alpha level that is stricter than the Pocock spending function, but the last two use a much less strict threshold, and the last look occurs at a level quite close to an alpha level without any correction. As we will see below, this is quite efficient, without requiring a noticeable increase in the sample size due to a lower alpha level at the last look.</p>
</div>
<div id="sample-size-for-sequential-designs" class="section level2">
<h2>
<span class="header-section-number">14.3</span> Sample Size for Sequential Designs</h2>
<p>Sequential designs require somewhat more participants than a fixed design at the final look, depending on how much the alpha level at this look is lowered due to the correction for multiple comparisons. Due to early stopping, sequential designs will on average require less participants.</p>
<p>Let’s first examine how many participants we would need in a fixed design, where we only analyze our data once. We have an alpha level of 0.05, and a Type 2 (beta) error of 0.1 - in other words, the desired power is 90%. We will perform one test, and assuming a normal distribution our critical Z-score would be 1.96, for an alpha level of 5%.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="sequential.html#cb138-1"></a><span class="co"># specify the design</span></span>
<span id="cb138-2"><a href="sequential.html#cb138-2"></a>seq_design &lt;-<span class="st"> </span><span class="kw">getDesignGroupSequential</span>(</span>
<span id="cb138-3"><a href="sequential.html#cb138-3"></a>  <span class="dt">kMax =</span> <span class="dv">1</span>,</span>
<span id="cb138-4"><a href="sequential.html#cb138-4"></a>  <span class="dt">typeOfDesign =</span> <span class="st">"P"</span>,</span>
<span id="cb138-5"><a href="sequential.html#cb138-5"></a>  <span class="dt">sided =</span> <span class="dv">2</span>,</span>
<span id="cb138-6"><a href="sequential.html#cb138-6"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb138-7"><a href="sequential.html#cb138-7"></a>  <span class="dt">beta =</span> <span class="fl">0.1</span></span>
<span id="cb138-8"><a href="sequential.html#cb138-8"></a>)</span>
<span id="cb138-9"><a href="sequential.html#cb138-9"></a><span class="co"># print a summary</span></span>
<span id="cb138-10"><a href="sequential.html#cb138-10"></a><span class="kw">summary</span>(seq_design)</span></code></pre></div>
<pre><code>## Fixed sample analysis
## 
## Stage                               Fixed 
## Efficacy boundary (z-value scale)   1.960 
## Two-sided local significance level 0.0500</code></pre>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="sequential.html#cb140-1"></a><span class="co"># perform a power analysis using rpact</span></span>
<span id="cb140-2"><a href="sequential.html#cb140-2"></a><span class="co"># By setting the alternative to 0.5 and the stDev to 1, we assume a Cohen's d of 0.5 for the alternative hypothesis.</span></span>
<span id="cb140-3"><a href="sequential.html#cb140-3"></a>power_res &lt;-<span class="st"> </span><span class="kw">getSampleSizeMeans</span>(</span>
<span id="cb140-4"><a href="sequential.html#cb140-4"></a>  <span class="dt">design =</span> seq_design,</span>
<span id="cb140-5"><a href="sequential.html#cb140-5"></a>  <span class="dt">groups =</span> <span class="dv">2</span>,</span>
<span id="cb140-6"><a href="sequential.html#cb140-6"></a>  <span class="dt">alternative =</span> <span class="fl">0.5</span>, </span>
<span id="cb140-7"><a href="sequential.html#cb140-7"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>, </span>
<span id="cb140-8"><a href="sequential.html#cb140-8"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span>,</span>
<span id="cb140-9"><a href="sequential.html#cb140-9"></a>  <span class="dt">normalApproximation =</span> <span class="ot">FALSE</span>)</span>
<span id="cb140-10"><a href="sequential.html#cb140-10"></a></span>
<span id="cb140-11"><a href="sequential.html#cb140-11"></a>power_res</span></code></pre></div>
<pre><code>## Design plan parameters and output for means:
## 
## Design parameters:
##   Significance level                           : 0.0500 
##   Type II error rate                           : 0.1 
##   Two-sided power                              : FALSE 
##   Test                                         : two-sided 
## 
## User defined parameters:
##   Alternatives                                 : 0.5 
## 
## Default parameters:
##   Normal approximation                         : FALSE 
##   Mean ratio                                   : FALSE 
##   Theta H0                                     : 0 
##   Standard deviation                           : 1 
##   Treatment groups                             : 2 
##   Planned allocation ratio                     : 1 
## 
## Sample size and output:
##   Number of subjects fixed                     : 170.1 
##   Number of subjects fixed (1)                 : 85.0 
##   Number of subjects fixed (2)                 : 85.0 
##   Lower critical values (effect scale)         : -0.303 
##   Upper critical values (effect scale)         : 0.303 
##   Local two-sided significance levels          : 0.0500 
## 
## Legend:
##   (i): values of treatment arm i</code></pre>
<p>We see we need 85 participants in each group, (or 86, since we always round the number of observations up, as we can not collect 0.03 of a participant), and so we need 172 participants in total (see G*Power, which rounds up values correctly). Because this is a fixed design, we can also compute this sample size using the <code>pwr</code> package in R or any other power analysis software.</p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="sequential.html#cb142-1"></a><span class="kw">pwr.t.test</span>(</span>
<span id="cb142-2"><a href="sequential.html#cb142-2"></a>  <span class="dt">d =</span> <span class="fl">0.5</span>,</span>
<span id="cb142-3"><a href="sequential.html#cb142-3"></a>  <span class="dt">sig.level =</span> <span class="fl">0.05</span>,</span>
<span id="cb142-4"><a href="sequential.html#cb142-4"></a>  <span class="dt">power =</span> <span class="fl">0.9</span>,</span>
<span id="cb142-5"><a href="sequential.html#cb142-5"></a>  <span class="dt">type=</span><span class="st">"two.sample"</span>,</span>
<span id="cb142-6"><a href="sequential.html#cb142-6"></a>  <span class="dt">alternative=</span><span class="st">"two.sided"</span></span>
<span id="cb142-7"><a href="sequential.html#cb142-7"></a>)<span class="op">$</span>n</span></code></pre></div>
<pre><code>## [1] 85.03128</code></pre>
<p>We can now examine our design above with 2 looks, a Pocock correction, a 2 sided test with an alpha of 0.05. We will look 2 times, and expect a true effect of d = 0.5.</p>
<div class="sourceCode" id="cb144"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb144-1"><a href="sequential.html#cb144-1"></a><span class="co"># Our 2 look design</span></span>
<span id="cb144-2"><a href="sequential.html#cb144-2"></a>seq_design &lt;-<span class="st"> </span><span class="kw">getDesignGroupSequential</span>(</span>
<span id="cb144-3"><a href="sequential.html#cb144-3"></a>  <span class="dt">kMax =</span> <span class="dv">2</span>,</span>
<span id="cb144-4"><a href="sequential.html#cb144-4"></a>  <span class="dt">typeOfDesign =</span> <span class="st">"P"</span>,</span>
<span id="cb144-5"><a href="sequential.html#cb144-5"></a>  <span class="dt">sided =</span> <span class="dv">2</span>,</span>
<span id="cb144-6"><a href="sequential.html#cb144-6"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb144-7"><a href="sequential.html#cb144-7"></a>  <span class="dt">beta =</span> <span class="fl">0.1</span></span>
<span id="cb144-8"><a href="sequential.html#cb144-8"></a>  )</span>
<span id="cb144-9"><a href="sequential.html#cb144-9"></a></span>
<span id="cb144-10"><a href="sequential.html#cb144-10"></a><span class="co"># Compute the sample size we need</span></span>
<span id="cb144-11"><a href="sequential.html#cb144-11"></a>power_res &lt;-<span class="st"> </span><span class="kw">getSampleSizeMeans</span>(</span>
<span id="cb144-12"><a href="sequential.html#cb144-12"></a>  <span class="dt">design =</span> seq_design,</span>
<span id="cb144-13"><a href="sequential.html#cb144-13"></a>  <span class="dt">groups =</span> <span class="dv">2</span>,</span>
<span id="cb144-14"><a href="sequential.html#cb144-14"></a>  <span class="dt">alternative =</span> <span class="fl">0.5</span>, </span>
<span id="cb144-15"><a href="sequential.html#cb144-15"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>, </span>
<span id="cb144-16"><a href="sequential.html#cb144-16"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span>,</span>
<span id="cb144-17"><a href="sequential.html#cb144-17"></a>  <span class="dt">normalApproximation =</span> <span class="ot">FALSE</span>)</span>
<span id="cb144-18"><a href="sequential.html#cb144-18"></a></span>
<span id="cb144-19"><a href="sequential.html#cb144-19"></a><span class="kw">summary</span>(power_res)</span></code></pre></div>
<pre><code>## Sample size calculation for a continuous endpoint
## 
## Sequential analysis with a maximum of 2 looks (group sequential design).
## The sample size was calculated for a two-sample t-test (two-sided),
## alternative = 0.5, standard deviation = 1, allocation ratio = 1, and power 90%.
## 
## Stage                                         1      2 
## Information rate                            50%   100% 
## Efficacy boundary (z-value scale)         2.178  2.178 
## Number of subjects                           94    188 
## Cumulative alpha spent                   0.0294 0.0500 
## Cumulative power                         0.5893 0.9000 
## Two-sided local significance level       0.0294 0.0294 
## Lower efficacy boundary (t)              -0.458 -0.321 
## Upper efficacy boundary (t)               0.458  0.321 
## Exit probability for efficacy (under H0) 0.0294 
## Exit probability for efficacy (under H1) 0.5893 
## 
## Legend:
##   (t): approximate treatment effect scale</code></pre>
<p>It is important to know that <code>rpact</code> returns the <em>total</em> number of subjects at look 1 (94, so 94/2 = 47 in each group), and the total sample size at look 2 (188, so 188/2 = 94 in each group). This means that at the second look, we are now collecting 188 instead of 172 participants. This is a consequence of lowering our alpha level at each look (from 0.05 to 0.0294). To compensate for the loss of power, we need to increase our sample size. HOwever, this is compensated by the fact that sometimes we will stop after look 1, and thus on average we will collect less participants (even though we might sometimes collect more participants than we would have, had we not used a sequential design). Rpact also computes the expected number of participants, in the long run, if the true effect size is d = 0.5.</p>
<div class="sourceCode" id="cb146"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb146-1"><a href="sequential.html#cb146-1"></a>power_res<span class="op">$</span>expectedNumberOfSubjectsH1</span></code></pre></div>
<pre><code>## [1] 131.9571</code></pre>
<p>So, in the long run, if the true effect size is d = 0.5, we will collect 132 observations (66 per condition), instead of 172 in total (or 86 per condition). Because power is a curve, and the true effect size is always unknown, it is useful to plot power across a range of possible effect sizes, so that we can explore the expected sample size, in the long run, if we use a sequential design, for different true effect sizes.</p>
<div class="sourceCode" id="cb148"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb148-1"><a href="sequential.html#cb148-1"></a><span class="co"># Use getPowerMeans and set max N to 188 based on analysis above</span></span>
<span id="cb148-2"><a href="sequential.html#cb148-2"></a>sample_res &lt;-<span class="st"> </span><span class="kw">getPowerMeans</span>(</span>
<span id="cb148-3"><a href="sequential.html#cb148-3"></a>  <span class="dt">design =</span> seq_design,</span>
<span id="cb148-4"><a href="sequential.html#cb148-4"></a>  <span class="dt">groups =</span> <span class="dv">2</span>,</span>
<span id="cb148-5"><a href="sequential.html#cb148-5"></a>  <span class="dt">alternative =</span> <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>), </span>
<span id="cb148-6"><a href="sequential.html#cb148-6"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>, </span>
<span id="cb148-7"><a href="sequential.html#cb148-7"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span>,</span>
<span id="cb148-8"><a href="sequential.html#cb148-8"></a>  <span class="dt">maxNumberOfSubjects =</span> <span class="dv">188</span>, <span class="co">#rounded up from 187.0829</span></span>
<span id="cb148-9"><a href="sequential.html#cb148-9"></a>  <span class="dt">normalApproximation =</span> <span class="ot">TRUE</span>)</span>
<span id="cb148-10"><a href="sequential.html#cb148-10"></a></span>
<span id="cb148-11"><a href="sequential.html#cb148-11"></a><span class="kw">plot</span>(sample_res, <span class="dt">type =</span> <span class="dv">6</span>)</span></code></pre></div>
<p><img src="Statistical_Inferences_files/figure-html/unnamed-chunk-69-1.png" width="672"></p>
<p>The blue line indicates the expected number of observations we need to collect. Not surprisingly, when the true effect size is 0, we will almost always continue data collection to the end. We will only stop if we observe a Type 1 error, which is rare, and thus the expected number of observations is very close to 120. On the other side of the graph we see the scenario for when the true effect size is d = 1. With such a large effect size, we will have high power at our first look, and we will almost always be able to stop at the first look. If the true effect size is 0.5, we see we can expect to collect 132 participants on average.</p>
<p>The Pocock correction leads to a substantially lower alpha level at the last look, which requires an increase in sample size to compensate. As we saw before, the O’Brien-Flemming spending function does not require such a severe reduction in the alpha level at the last look. Let’s see how well this performs. With 2 looks, this design would not need an increase in sample size at all, yet lower the expected number of observations we would collect to 145. However, let’s add 2 additional looks at the data, for 4 looks in total.</p>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="sequential.html#cb149-1"></a><span class="co"># Now a 4 look OF design</span></span>
<span id="cb149-2"><a href="sequential.html#cb149-2"></a>seq_design &lt;-<span class="st"> </span><span class="kw">getDesignGroupSequential</span>(</span>
<span id="cb149-3"><a href="sequential.html#cb149-3"></a>  <span class="dt">kMax =</span> <span class="dv">4</span>,</span>
<span id="cb149-4"><a href="sequential.html#cb149-4"></a>  <span class="dt">typeOfDesign =</span> <span class="st">"OF"</span>,</span>
<span id="cb149-5"><a href="sequential.html#cb149-5"></a>  <span class="dt">sided =</span> <span class="dv">2</span>,</span>
<span id="cb149-6"><a href="sequential.html#cb149-6"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb149-7"><a href="sequential.html#cb149-7"></a>  <span class="dt">beta =</span> <span class="fl">0.1</span></span>
<span id="cb149-8"><a href="sequential.html#cb149-8"></a>  )</span>
<span id="cb149-9"><a href="sequential.html#cb149-9"></a><span class="kw">summary</span>(seq_design)</span></code></pre></div>
<pre><code>## Sequential analysis with a maximum of 4 looks (group sequential design)
## 
## Stage                                    1       2       3       4 
## Information rate                       25%     50%     75%    100% 
## Efficacy boundary (z-value scale)    4.049   2.863   2.337   2.024 
## Cumulative alpha spent             &lt;0.0001  0.0042  0.0209  0.0500 
## Two-sided local significance level &lt;0.0001  0.0042  0.0194  0.0429</code></pre>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="sequential.html#cb151-1"></a>power_res &lt;-<span class="st"> </span><span class="kw">getSampleSizeMeans</span>(</span>
<span id="cb151-2"><a href="sequential.html#cb151-2"></a>  <span class="dt">design =</span> seq_design,</span>
<span id="cb151-3"><a href="sequential.html#cb151-3"></a>  <span class="dt">groups =</span> <span class="dv">2</span>,</span>
<span id="cb151-4"><a href="sequential.html#cb151-4"></a>  <span class="dt">alternative =</span> <span class="fl">0.5</span>, </span>
<span id="cb151-5"><a href="sequential.html#cb151-5"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>, </span>
<span id="cb151-6"><a href="sequential.html#cb151-6"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span>,</span>
<span id="cb151-7"><a href="sequential.html#cb151-7"></a>  <span class="dt">normalApproximation =</span> <span class="ot">FALSE</span>)</span>
<span id="cb151-8"><a href="sequential.html#cb151-8"></a></span>
<span id="cb151-9"><a href="sequential.html#cb151-9"></a><span class="kw">summary</span>(power_res)</span></code></pre></div>
<pre><code>## Sample size calculation for a continuous endpoint
## 
## Sequential analysis with a maximum of 4 looks (group sequential design).
## The sample size was calculated for a two-sample t-test (two-sided),
## alternative = 0.5, standard deviation = 1, allocation ratio = 1, and power 90%.
## 
## Stage                                          1       2       3       4 
## Information rate                             25%     50%     75%    100% 
## Efficacy boundary (z-value scale)          4.049   2.863   2.337   2.024 
## Number of subjects                            44      87     131     174 
## Cumulative alpha spent                   &lt;0.0001  0.0042  0.0209  0.0500 
## Cumulative power                          0.0080  0.2930  0.6960  0.9000 
## Two-sided local significance level       &lt;0.0001  0.0042  0.0194  0.0429 
## Lower efficacy boundary (t)               -1.370  -0.631  -0.415  -0.309 
## Upper efficacy boundary (t)                1.370   0.631   0.415   0.309 
## Exit probability for efficacy (under H0) &lt;0.0001  0.0042  0.0167 
## Exit probability for efficacy (under H1)  0.0080  0.2850  0.4031 
## 
## Legend:
##   (t): approximate treatment effect scale</code></pre>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="sequential.html#cb153-1"></a>sample_res &lt;-<span class="st"> </span><span class="kw">getPowerMeans</span>(</span>
<span id="cb153-2"><a href="sequential.html#cb153-2"></a>  <span class="dt">design =</span> seq_design,</span>
<span id="cb153-3"><a href="sequential.html#cb153-3"></a>  <span class="dt">groups =</span> <span class="dv">2</span>,</span>
<span id="cb153-4"><a href="sequential.html#cb153-4"></a>  <span class="dt">alternative =</span> <span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="fl">0.1</span>), </span>
<span id="cb153-5"><a href="sequential.html#cb153-5"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>, </span>
<span id="cb153-6"><a href="sequential.html#cb153-6"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span>,</span>
<span id="cb153-7"><a href="sequential.html#cb153-7"></a>  <span class="dt">maxNumberOfSubjects =</span> <span class="dv">174</span>, </span>
<span id="cb153-8"><a href="sequential.html#cb153-8"></a>  <span class="dt">normalApproximation =</span> <span class="ot">TRUE</span>)</span></code></pre></div>
<p>We see that with 4 looks, we will not need to increase the maximum sample size a lot, as we only need 174 instead of 172 participants.</p>
<div class="sourceCode" id="cb154"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb154-1"><a href="sequential.html#cb154-1"></a>power_res<span class="op">$</span>maxNumberOfSubjects</span></code></pre></div>
<pre><code>## [1] 173.8317</code></pre>
<p>There is a noticeable reduction in the average number of samples we can expect to collect, if the true effect size is d = 0.5.</p>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="sequential.html#cb156-1"></a>power_res<span class="op">$</span>expectedNumberOfSubjectsH1</span></code></pre></div>
<pre><code>## [1] 130.5056</code></pre>
<p>If we plot this expected sample size across different true effect sizes, we see that we become more efficient - only at the cost of 1) analyzing our data 4 times, and 2) needing to preregister our analysis plan. Preregistration is required, because sequential analyses give a lot of additional freedom that can possibly inflate error rates substantially. So performing computations as performed here, and preregistering your analysis plan, is required - but worth it.</p>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="sequential.html#cb158-1"></a><span class="kw">plot</span>(sample_res, <span class="dt">type =</span> <span class="dv">6</span>)</span></code></pre></div>
<p><img src="Statistical_Inferences_files/figure-html/unnamed-chunk-73-1.png" width="672"></p>
<p>We can redo the power analysis in for the original 2 look design in gsDesign. The graph shows that if the true effect size is d = 0.5 we have approximately 59% power after the first look, and 90% power after the second look, given our adjusted alpha level.</p>
<div class="sourceCode" id="cb159"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb159-1"><a href="sequential.html#cb159-1"></a>seqdesign &lt;-<span class="st"> </span><span class="kw">gsDesign</span>(</span>
<span id="cb159-2"><a href="sequential.html#cb159-2"></a>  <span class="dt">k =</span> <span class="dv">2</span>, <span class="co"># k = number of looks = 2</span></span>
<span id="cb159-3"><a href="sequential.html#cb159-3"></a>  <span class="dt">test.type =</span> <span class="dv">2</span>,</span>
<span id="cb159-4"><a href="sequential.html#cb159-4"></a>  <span class="dt">alpha =</span> <span class="fl">.025</span>,</span>
<span id="cb159-5"><a href="sequential.html#cb159-5"></a>  <span class="dt">beta =</span> <span class="fl">0.1</span>,</span>
<span id="cb159-6"><a href="sequential.html#cb159-6"></a>  <span class="dt">sfu =</span> <span class="st">"Pocock"</span>,</span>
<span id="cb159-7"><a href="sequential.html#cb159-7"></a>  <span class="co"># gsDesign calculates d as a within subjects d. </span></span>
<span id="cb159-8"><a href="sequential.html#cb159-8"></a>  <span class="co"># We need the /sqrt(2) to turn it from d_z into d</span></span>
<span id="cb159-9"><a href="sequential.html#cb159-9"></a>  <span class="dt">delta =</span> <span class="fl">0.5</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span>), </span>
<span id="cb159-10"><a href="sequential.html#cb159-10"></a>  <span class="dt">delta0 =</span> <span class="dv">0</span>,</span>
<span id="cb159-11"><a href="sequential.html#cb159-11"></a>  <span class="dt">delta1 =</span> <span class="fl">0.5</span></span>
<span id="cb159-12"><a href="sequential.html#cb159-12"></a>) <span class="co"># spending function = Pocock</span></span>
<span id="cb159-13"><a href="sequential.html#cb159-13"></a></span>
<span id="cb159-14"><a href="sequential.html#cb159-14"></a><span class="co"># All required info is in:</span></span>
<span id="cb159-15"><a href="sequential.html#cb159-15"></a>seqdesign</span></code></pre></div>
<pre><code>## Symmetric two-sided group sequential design with
## 90 % power and 2.5 % Type I Error.
## Spending computations assume trial stops
## if a bound is crossed.
## 
##              
##   Analysis N   Z   Nominal p  Spend
##          1 47 2.18    0.0147 0.0147
##          2 93 2.18    0.0147 0.0103
##      Total                   0.0250 
## 
## ++ alpha spending:
##  Pocock boundary.
## 
## Boundary crossing probabilities and expected sample size
## assume any cross stops the trial
## 
## Upper boundary (power or Type I Error)
##           Analysis
##    Theta      1      2 Total E{N}
##   0.0000 0.0147 0.0103 0.025 91.1
##   0.3536 0.5893 0.3107 0.900 65.2
## 
## Lower boundary (futility or Type II Error)
##           Analysis
##    Theta      1      2 Total
##   0.0000 0.0147 0.0103 0.025
##   0.3536 0.0000 0.0000 0.000</code></pre>
<div class="sourceCode" id="cb161"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb161-1"><a href="sequential.html#cb161-1"></a><span class="co"># We can look at the sample sizes as expected compared to a fixed design</span></span>
<span id="cb161-2"><a href="sequential.html#cb161-2"></a><span class="kw">plot</span>(seqdesign, <span class="dt">plottype =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="Statistical_Inferences_files/figure-html/unnamed-chunk-74-1.png" width="672"></p>
<div id="alpha-spending-functions" class="section level3">
<h3>
<span class="header-section-number">14.3.1</span> Alpha spending functions</h3>
<p>The Pocock and O’Brien-Fleming spending functions we discussed so far have an important limitation <span class="citation">(Proschan et al., <label for="tufte-mn-93" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-93" class="margin-toggle">2006<span class="marginnote">Proschan, M. A., Lan, K. K. G., &amp; Wittes, J. T. (2006). <em>Statistical monitoring of clinical trials: A unified approach</em>. Springer.</span>)</span>. They require a pre-specified number of looks (e.g., 4) that is equally spaced (e.g., after 25%, 50%, 75%, and 100%). It is not always possible to stop data collection exactly after for example the 50th participant, because you need to pause data collection to analyze the data, which might not be possible if additional sessions are scheduled on the day the 50th observation is collected. An important contribution to the sequential testing literature was made by Lan and DeMets <span class="citation">(<label for="tufte-mn-94" class="margin-toggle">⊕</label><input type="checkbox" id="tufte-mn-94" class="margin-toggle">1983<span class="marginnote">Lan, K. K. G., &amp; DeMets, D. L. (1983). Discrete Sequential Boundaries for Clinical Trials. <em>Biometrika</em>, <em>70</em>(3), 659. <a href="https://doi.org/10.2307/2336502">https://doi.org/10.2307/2336502</a></span>)</span> who created <strong>alpha spending functions</strong>, where the boundary at the decision time does not depend on the future decision times or the total number of decision times.</p>
<p>We see the O’Brien-Fleming-like alpha spending function is quite similar to the discrete O’Brien-Fleming bounds.</p>
<div class="figure">
<span id="fig:spending-comparison-2"></span>
<p class="caption marginnote shownote">
Figure 14.7: Comparison of the O’Brien-Fleming boundaries and the O’Brien-FLiming-like alpha spending function.
</p>
<img src="Statistical_Inferences_files/figure-html/spending-comparison-2-1.png" alt="Comparison of the O'Brien-Fleming boundaries and the O'Brien-FLiming-like alpha spending function." width="672">
</div>
<p>There is a wide range of alpha spending functions possible. In addition to a Pocock-type and O’Brien-Fleming-type alpha spending function RPACT has the Kim &amp; DeMets alpha spending function and the Hwang, Shi &amp; DeCani alpha spending function, but users can also specify a custom spending function. Again, the main benefit of these spending functions is that neither the number nor the timing of the looks needs to be specified in advance, which makes alpha spending approaches much more flexible. However, it is important that the decision to perform an interim analysis is not based on collected data, as this can still increase the Type 1 error rate.</p>
<!-- ```{r spending-comparison-3, fig.margin=FALSE, echo=FALSE, fig.cap="Comparison of different alpha spending functions."} -->
<!-- #Pocock type -->
<!-- d1 <- getDesignGroupSequential(typeOfDesign = "asP", -->
<!--                                kMax = 5)  -->
<!-- # OF-like continuous spending function -->
<!-- d2 <- getDesignGroupSequential(typeOfDesign = "asOF", -->
<!--                                kMax = 5) -->
<!-- d3 <- getDesignGroupSequential(typeOfDesign = "asKD", -->
<!--                                kMax = 5) -->
<!-- d4 <- getDesignGroupSequential(typeOfDesign = "asHSD", -->
<!--                                kMax = 5) -->
<!-- designSet <-getDesignSet(designs = c(d1, d2, d3, d4),  -->
<!--                          variedParameters = "typeOfDesign") -->
<!-- plot(designSet, -->
<!--      type = 1) -->
<!-- ``` -->
</div>
<div id="updating-boundaries-during-an-experiment" class="section level3">
<h3>
<span class="header-section-number">14.3.2</span> Updating Boundaries During an Experiment</h3>
<p>Although alpha spending functions control the Type 1 error rate even when there are deviations from the pre-planned looks, this does require recalculating the boundaries based on the amount of information that has been observed. In this example, we follow an <a href="https://vignettes.rpact.org/html/rpact_boundary_update_example.html">RPACT vignette</a>. Imagine a two-sided design with an O’Brien-Fleming-type alpha-spending function, and alpha of 0.025, a desired power of 90%, with 3 looks, planned when 50%, 75%, and 100% of our maximum sample has been collected.</p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="sequential.html#cb162-1"></a><span class="co"># Original design:</span></span>
<span id="cb162-2"><a href="sequential.html#cb162-2"></a>seq_design &lt;-<span class="st"> </span><span class="kw">getDesignGroupSequential</span>(</span>
<span id="cb162-3"><a href="sequential.html#cb162-3"></a>  <span class="dt">sided =</span> <span class="dv">2</span>,</span>
<span id="cb162-4"><a href="sequential.html#cb162-4"></a>  <span class="dt">kMax =</span> <span class="dv">3</span>,</span>
<span id="cb162-5"><a href="sequential.html#cb162-5"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb162-6"><a href="sequential.html#cb162-6"></a>  <span class="dt">beta =</span> <span class="fl">0.1</span>,</span>
<span id="cb162-7"><a href="sequential.html#cb162-7"></a>  <span class="dt">informationRates =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="fl">0.75</span>, <span class="dv">1</span>),</span>
<span id="cb162-8"><a href="sequential.html#cb162-8"></a>  <span class="dt">typeOfDesign =</span> <span class="st">"asOF"</span></span>
<span id="cb162-9"><a href="sequential.html#cb162-9"></a>)</span>
<span id="cb162-10"><a href="sequential.html#cb162-10"></a></span>
<span id="cb162-11"><a href="sequential.html#cb162-11"></a><span class="co"># Initial sample size calculation</span></span>
<span id="cb162-12"><a href="sequential.html#cb162-12"></a>sampleSizeResult &lt;-<span class="st"> </span><span class="kw">getSampleSizeMeans</span>(</span>
<span id="cb162-13"><a href="sequential.html#cb162-13"></a>  <span class="dt">design =</span> seq_design,</span>
<span id="cb162-14"><a href="sequential.html#cb162-14"></a>  <span class="dt">groups =</span> <span class="dv">2</span>,</span>
<span id="cb162-15"><a href="sequential.html#cb162-15"></a>  <span class="dt">alternative =</span> <span class="fl">0.5</span>,</span>
<span id="cb162-16"><a href="sequential.html#cb162-16"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>,</span>
<span id="cb162-17"><a href="sequential.html#cb162-17"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span>,</span>
<span id="cb162-18"><a href="sequential.html#cb162-18"></a>  <span class="dt">normalApproximation =</span> <span class="ot">FALSE</span></span>
<span id="cb162-19"><a href="sequential.html#cb162-19"></a>)</span>
<span id="cb162-20"><a href="sequential.html#cb162-20"></a></span>
<span id="cb162-21"><a href="sequential.html#cb162-21"></a><span class="co"># Summarize design</span></span>
<span id="cb162-22"><a href="sequential.html#cb162-22"></a><span class="kw">summary</span>(sampleSizeResult)</span></code></pre></div>
<pre><code>## Sample size calculation for a continuous endpoint
## 
## Sequential analysis with a maximum of 3 looks (group sequential design).
## The sample size was calculated for a two-sample t-test (two-sided),
## alternative = 0.5, standard deviation = 1, allocation ratio = 1, and power 90%.
## 
## Stage                                         1      2      3 
## Information rate                            50%    75%   100% 
## Efficacy boundary (z-value scale)         2.963  2.359  2.014 
## Number of subjects                           87    130    174 
## Cumulative alpha spent                   0.0031 0.0193 0.0500 
## Cumulative power                         0.2580 0.6853 0.9000 
## Two-sided local significance level       0.0031 0.0183 0.0440 
## Lower efficacy boundary (t)              -0.656 -0.419 -0.308 
## Upper efficacy boundary (t)               0.656  0.419  0.308 
## Exit probability for efficacy (under H0) 0.0031 0.0162 
## Exit probability for efficacy (under H1) 0.2580 0.4273 
## 
## Legend:
##   (t): approximate treatment effect scale</code></pre>
<p>The a-priori power analysis shows that, assuming an effect size of 0.5, we plan to look after 87, 130, 174 observations. Now imagine that due to logistical issues, we do not have to ability to analyze the data until we have collected data from 95, instead of 87, participants. So our first look at the data does not occur at 50% of our sample, but at 95/174 = 54.6%. We can recalculate the alpha levels we should use for this and future looks, and update our sample size calculation. This reveals we should use an alpha level of 0.0048 for the current look (instead of 0.0031). and the next look should occur after 131 participants in total, not 130. We see the differences are not very substantial, but if the deviation from the planned looks increases, the changes might become more impactful. Note that even if the number of looks was not pre-planned, we would use similar calculations at each look, but instead increase the number of looks (e.g., perform an analysis with 1 interim look at time = 95/174, and if the second look occurs after 146 participants, we would run an analysis with two interim looks, one at 95/174 and a second at 146/174, see Proschan et al., 2006, chapter 5).</p>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="sequential.html#cb164-1"></a>seq_design_<span class="dv">2</span> &lt;-<span class="st"> </span><span class="kw">getDesignGroupSequential</span>(</span>
<span id="cb164-2"><a href="sequential.html#cb164-2"></a>  <span class="dt">sided =</span> <span class="dv">2</span>,</span>
<span id="cb164-3"><a href="sequential.html#cb164-3"></a>  <span class="dt">kMax =</span> <span class="dv">3</span>,</span>
<span id="cb164-4"><a href="sequential.html#cb164-4"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb164-5"><a href="sequential.html#cb164-5"></a>  <span class="dt">beta =</span> <span class="fl">0.1</span>,</span>
<span id="cb164-6"><a href="sequential.html#cb164-6"></a>  <span class="dt">informationRates =</span> <span class="kw">c</span>(<span class="dv">95</span><span class="op">/</span><span class="dv">174</span>, <span class="fl">0.75</span>, <span class="dv">1</span>),</span>
<span id="cb164-7"><a href="sequential.html#cb164-7"></a>  <span class="dt">typeOfDesign =</span> <span class="st">"asOF"</span></span>
<span id="cb164-8"><a href="sequential.html#cb164-8"></a>)</span>
<span id="cb164-9"><a href="sequential.html#cb164-9"></a></span>
<span id="cb164-10"><a href="sequential.html#cb164-10"></a><span class="kw">summary</span>(seq_design_<span class="dv">2</span>)</span></code></pre></div>
<pre><code>## Sequential analysis with a maximum of 3 looks (group sequential design)
## 
## Stage                                   1      2      3 
## Information rate                    54.6%    75%   100% 
## Efficacy boundary (z-value scale)   2.818  2.370  2.015 
## Cumulative alpha spent             0.0048 0.0193 0.0500 
## Two-sided local significance level 0.0048 0.0178 0.0439</code></pre>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="sequential.html#cb166-1"></a><span class="co"># Update power analysis</span></span>
<span id="cb166-2"><a href="sequential.html#cb166-2"></a></span>
<span id="cb166-3"><a href="sequential.html#cb166-3"></a>power_update_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="kw">getPowerMeans</span>(</span>
<span id="cb166-4"><a href="sequential.html#cb166-4"></a>  <span class="dt">design =</span> seq_design_<span class="dv">2</span>,</span>
<span id="cb166-5"><a href="sequential.html#cb166-5"></a>  <span class="dt">groups =</span> <span class="dv">2</span>,</span>
<span id="cb166-6"><a href="sequential.html#cb166-6"></a>  <span class="dt">alternative =</span> <span class="fl">0.5</span>, </span>
<span id="cb166-7"><a href="sequential.html#cb166-7"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>, </span>
<span id="cb166-8"><a href="sequential.html#cb166-8"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span>,</span>
<span id="cb166-9"><a href="sequential.html#cb166-9"></a>  <span class="dt">maxNumberOfSubjects =</span> <span class="dv">174</span>, </span>
<span id="cb166-10"><a href="sequential.html#cb166-10"></a>  <span class="dt">normalApproximation =</span> <span class="ot">TRUE</span>)</span>
<span id="cb166-11"><a href="sequential.html#cb166-11"></a><span class="kw">summary</span>(power_update_<span class="dv">1</span>)</span></code></pre></div>
<pre><code>## Power calculation for a continuous endpoint
## 
## Sequential analysis with a maximum of 3 looks (group sequential design).
## The results were calculated for a two-sample t-test (two-sided),
## alternative = 0.5, standard deviation = 1, allocation ratio = 1.
## 
## Stage                                         1      2      3 
## Information rate                          54.6%    75%   100% 
## Efficacy boundary (z-value scale)         2.818  2.370  2.015 
## Number of subjects                           96    131    174 
## Cumulative alpha spent                   0.0048 0.0193 0.0500 
## Cumulative power                         0.3516 0.6917 0.9045 
## Two-sided local significance level       0.0048 0.0178 0.0439 
## Lower efficacy boundary (t)              -0.578 -0.415 -0.306 
## Upper efficacy boundary (t)               0.578  0.415  0.306 
## Exit probability for efficacy (under H0) 0.0048 0.0145 
## Exit probability for efficacy (under H1) 0.3516 0.3401 
## 
## Legend:
##   (t): approximate treatment effect scale</code></pre>
</div>
</div>
<div id="test-for-non-inferiority" class="section level2">
<h2>
<span class="header-section-number">14.4</span> Test for non-inferiority</h2>
<p>In an equivalence</p>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="sequential.html#cb168-1"></a><span class="co"># Trying gset package from https://journal.r-project.org/archive/2014-2/liu.pdf</span></span>
<span id="cb168-2"><a href="sequential.html#cb168-2"></a></span>
<span id="cb168-3"><a href="sequential.html#cb168-3"></a><span class="co">#### specify the parameters</span></span>
<span id="cb168-4"><a href="sequential.html#cb168-4"></a><span class="co"># The bound divided by the sigma equals the bound in Cohen's d. </span></span>
<span id="cb168-5"><a href="sequential.html#cb168-5"></a>L &lt;-<span class="st"> </span><span class="fl">-0.2</span></span>
<span id="cb168-6"><a href="sequential.html#cb168-6"></a>U &lt;-<span class="st"> </span><span class="fl">0.2</span></span>
<span id="cb168-7"><a href="sequential.html#cb168-7"></a>theta &lt;-<span class="st"> </span><span class="dv">0</span></span>
<span id="cb168-8"><a href="sequential.html#cb168-8"></a>sigma &lt;-<span class="st"> </span><span class="fl">0.4</span></span>
<span id="cb168-9"><a href="sequential.html#cb168-9"></a>alpha &lt;-<span class="st"> </span><span class="fl">0.05</span></span>
<span id="cb168-10"><a href="sequential.html#cb168-10"></a>beta &lt;-<span class="st"> </span><span class="fl">0.05</span></span>
<span id="cb168-11"><a href="sequential.html#cb168-11"></a>K &lt;-<span class="st"> </span><span class="dv">4</span></span>
<span id="cb168-12"><a href="sequential.html#cb168-12"></a>r &lt;-<span class="st"> </span><span class="dv">1</span></span>
<span id="cb168-13"><a href="sequential.html#cb168-13"></a></span>
<span id="cb168-14"><a href="sequential.html#cb168-14"></a><span class="co">#### Therefore, the sample size in the non-sequential setting</span></span>
<span id="cb168-15"><a href="sequential.html#cb168-15"></a></span>
<span id="cb168-16"><a href="sequential.html#cb168-16"></a>n.fix &lt;-<span class="st"> </span><span class="kw">nfix</span>(r, L, U, theta, sigma, alpha, beta)</span>
<span id="cb168-17"><a href="sequential.html#cb168-17"></a>n.fix</span></code></pre></div>
<pre><code>## $n1
## [1] 104
## 
## $n2
## [1] 104</code></pre>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="sequential.html#cb170-1"></a><span class="co"># Equals the power analysis using TOSTER!</span></span>
<span id="cb170-2"><a href="sequential.html#cb170-2"></a>TOSTER<span class="op">::</span><span class="kw">powerTOSTtwo</span>(<span class="dt">alpha=</span>alpha, </span>
<span id="cb170-3"><a href="sequential.html#cb170-3"></a>                     <span class="dt">statistical_power=</span>(<span class="dv">1</span><span class="op">-</span>beta), </span>
<span id="cb170-4"><a href="sequential.html#cb170-4"></a>                     <span class="dt">low_eqbound_d=</span><span class="op">-</span><span class="fl">0.5</span>, </span>
<span id="cb170-5"><a href="sequential.html#cb170-5"></a>                     <span class="dt">high_eqbound_d=</span><span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## The required sample size to achieve 95 % power with equivalence bounds of -0.5 and 0.5 is 104 per group, or 208 in total.</code></pre>
<pre><code>## [1] 103.9577</code></pre>
<div class="sourceCode" id="cb173"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb173-1"><a href="sequential.html#cb173-1"></a>bound1&lt;-<span class="st"> </span><span class="kw">equivonly</span>(L, U,  sigma, n.fix<span class="op">$</span>n1, n.fix<span class="op">$</span>n2, <span class="dv">1</span><span class="op">:</span>K<span class="op">/</span>K, alpha, beta)</span>
<span id="cb173-2"><a href="sequential.html#cb173-2"></a></span>
<span id="cb173-3"><a href="sequential.html#cb173-3"></a>bound1</span></code></pre></div>
<pre><code>## $typeI
## [1] 0.01273534 0.02531248 0.03773339 0.05000000
## 
## $equivL
## [1] 1.774063 2.196442 2.162304 1.998837
## 
## $equivU
## [1] -1.774063 -2.196442 -2.162304 -1.998837</code></pre>
<div class="sourceCode" id="cb175"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb175-1"><a href="sequential.html#cb175-1"></a><span class="co">####  the boundary plot can be regenerated by using </span></span>
<span id="cb175-2"><a href="sequential.html#cb175-2"></a></span>
<span id="cb175-3"><a href="sequential.html#cb175-3"></a><span class="kw">figureE</span>(bound1, K)</span></code></pre></div>
<p><img src="Statistical_Inferences_files/figure-html/unnamed-chunk-77-1.png" width="672"></p>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="sequential.html#cb176-1"></a>bound1<span class="op">$</span>typeI</span></code></pre></div>
<pre><code>## [1] 0.01273534 0.02531248 0.03773339 0.05000000</code></pre>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="sequential.html#cb178-1"></a>oc_res1 &lt;-<span class="st"> </span><span class="kw">oc</span>(L,U,<span class="dt">theta =</span> L,sigma,K,<span class="dv">69</span>,<span class="dv">69</span>,bound1,<span class="dt">futility =</span> <span class="ot">FALSE</span>) <span class="co">#True effect lower bound</span></span>
<span id="cb178-2"><a href="sequential.html#cb178-2"></a>oc_res1</span></code></pre></div>
<pre><code>## $reject.rate
## [1] 0.0326
## 
## $En1
## [1] 68.6
## 
## $En2
## [1] 68.6
## 
## $prob.stop
## [1] 0.0025 0.0022 0.0139 0.9814
## 
## $prob.stopE
## [1] 0.0025 0.0022 0.0139 0.0140
## 
## $prob.stopF
## [1] 0 0 0 0</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="sequential.html#cb180-1"></a>oc_res2 &lt;-<span class="st"> </span><span class="kw">oc</span>(L,U,<span class="dt">theta =</span> <span class="dv">0</span>,sigma,K,<span class="dv">69</span>,<span class="dv">69</span>,bound1,<span class="dt">futility =</span> <span class="ot">FALSE</span>) <span class="co"># no effect</span></span>
<span id="cb180-2"><a href="sequential.html#cb180-2"></a>oc_res2</span></code></pre></div>
<pre><code>## $reject.rate
## [1] 0.6762
## 
## $En1
## [1] 62.8
## 
## $En2
## [1] 62.8
## 
## $prob.stop
## [1] 0.0097 0.0273 0.2804 0.6826
## 
## $prob.stopE
## [1] 0.0097 0.0273 0.2804 0.3588
## 
## $prob.stopF
## [1] 0 0 0 0</code></pre>
<div class="sourceCode" id="cb182"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb182-1"><a href="sequential.html#cb182-1"></a><span class="kw">sum</span>(oc_res1<span class="op">$</span>prob.stopE)</span></code></pre></div>
<pre><code>## [1] 0.0326</code></pre>
<div class="sourceCode" id="cb184"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb184-1"><a href="sequential.html#cb184-1"></a>sampleSizeResult &lt;-<span class="st"> </span><span class="kw">getSampleSizeMeans</span>(<span class="dt">alternative =</span> <span class="fl">0.5</span>, <span class="dt">stDev =</span> <span class="dv">1</span>, <span class="dt">sided =</span> <span class="dv">2</span>, <span class="dt">alpha =</span> <span class="fl">0.05</span>, <span class="dt">beta =</span> <span class="fl">0.2</span>)</span>
<span id="cb184-2"><a href="sequential.html#cb184-2"></a><span class="kw">summary</span>(sampleSizeResult)</span></code></pre></div>
<pre><code>## Sample size calculation for a continuous endpoint
## 
## Fixed sample analysis.
## The sample size was calculated for a two-sample t-test (two-sided),
## alternative = 0.5, standard deviation = 1, allocation ratio = 1, and power 80%.
## 
## Stage                               Fixed 
## Efficacy boundary (z-value scale)   1.960 
## Number of subjects                    128 
## Two-sided local significance level 0.0500 
## Lower efficacy boundary (t)        -0.350 
## Upper efficacy boundary (t)         0.350 
## 
## Legend:
##   (t): approximate treatment effect scale</code></pre>
<div class="sourceCode" id="cb186"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb186-1"><a href="sequential.html#cb186-1"></a>powerResult &lt;-<span class="st"> </span><span class="kw">getPowerMeans</span>(</span>
<span id="cb186-2"><a href="sequential.html#cb186-2"></a>  <span class="dt">alternative =</span> <span class="dv">0</span><span class="op">:</span><span class="dv">1</span>,</span>
<span id="cb186-3"><a href="sequential.html#cb186-3"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>,</span>
<span id="cb186-4"><a href="sequential.html#cb186-4"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span>,</span>
<span id="cb186-5"><a href="sequential.html#cb186-5"></a>  <span class="dt">maxNumberOfSubjects =</span> <span class="dv">200</span>,</span>
<span id="cb186-6"><a href="sequential.html#cb186-6"></a>  <span class="dt">sided =</span> <span class="dv">2</span>,</span>
<span id="cb186-7"><a href="sequential.html#cb186-7"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span></span>
<span id="cb186-8"><a href="sequential.html#cb186-8"></a>)</span>
<span id="cb186-9"><a href="sequential.html#cb186-9"></a><span class="kw">plot</span>(powerResult, <span class="dt">type =</span> <span class="dv">7</span>) <span class="co"># powercurve</span></span></code></pre></div>
<p><img src="Statistical_Inferences_files/figure-html/unnamed-chunk-78-1.png" width="672"></p>
<div class="sourceCode" id="cb187"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb187-1"><a href="sequential.html#cb187-1"></a><span class="co"># Now for a non-inferiority trial!</span></span>
<span id="cb187-2"><a href="sequential.html#cb187-2"></a></span>
<span id="cb187-3"><a href="sequential.html#cb187-3"></a>sampleSizeNoninf &lt;-<span class="st"> </span><span class="kw">getSampleSizeMeans</span>(</span>
<span id="cb187-4"><a href="sequential.html#cb187-4"></a>  <span class="dt">thetaH0 =</span> <span class="fl">-0.5</span>,</span>
<span id="cb187-5"><a href="sequential.html#cb187-5"></a>  <span class="dt">alternative =</span> <span class="dv">0</span>,</span>
<span id="cb187-6"><a href="sequential.html#cb187-6"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>,</span>
<span id="cb187-7"><a href="sequential.html#cb187-7"></a>  <span class="dt">alpha =</span> <span class="fl">0.025</span>,</span>
<span id="cb187-8"><a href="sequential.html#cb187-8"></a>  <span class="dt">beta =</span> <span class="fl">0.2</span>,</span>
<span id="cb187-9"><a href="sequential.html#cb187-9"></a>  <span class="dt">sided =</span> <span class="dv">1</span></span>
<span id="cb187-10"><a href="sequential.html#cb187-10"></a>)</span>
<span id="cb187-11"><a href="sequential.html#cb187-11"></a>sampleSizeNoninf</span></code></pre></div>
<pre><code>## Design plan parameters and output for means:
## 
## Design parameters:
##   Significance level                           : 0.0250 
##   Type II error rate                           : 0.2 
##   Test                                         : one-sided 
## 
## User defined parameters:
##   Theta H0                                     : -0.5 
##   Alternatives                                 : 0 
## 
## Default parameters:
##   Normal approximation                         : FALSE 
##   Mean ratio                                   : FALSE 
##   Standard deviation                           : 1 
##   Treatment groups                             : 2 
##   Planned allocation ratio                     : 1 
## 
## Sample size and output:
##   Number of subjects fixed                     : 127.5 
##   Number of subjects fixed (1)                 : 63.8 
##   Number of subjects fixed (2)                 : 63.8 
##   Critical values (effect scale)               : -0.150 
##   Local one-sided significance levels          : 0.0250 
## 
## Legend:
##   (i): values of treatment arm i</code></pre>
<div class="sourceCode" id="cb189"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb189-1"><a href="sequential.html#cb189-1"></a><span class="kw">summary</span>(sampleSizeNoninf)</span></code></pre></div>
<pre><code>## Sample size calculation for a continuous endpoint
## 
## Fixed sample analysis.
## The sample size was calculated for a two-sample t-test (one-sided),
## alternative = 0, standard deviation = 1, allocation ratio = 1, and power 80%.
## 
## Stage                               Fixed 
## Efficacy boundary (z-value scale)   1.960 
## Number of subjects                    128 
## One-sided local significance level 0.0250 
## Efficacy boundary (t)              -0.150 
## 
## Legend:
##   (t): approximate treatment effect scale</code></pre>
<div class="sourceCode" id="cb191"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb191-1"><a href="sequential.html#cb191-1"></a>design &lt;-<span class="st"> </span><span class="kw">getDesignGroupSequential</span>(</span>
<span id="cb191-2"><a href="sequential.html#cb191-2"></a>  <span class="dt">sided =</span> <span class="dv">2</span>,</span>
<span id="cb191-3"><a href="sequential.html#cb191-3"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb191-4"><a href="sequential.html#cb191-4"></a>  <span class="dt">beta =</span> <span class="fl">0.2</span>,</span>
<span id="cb191-5"><a href="sequential.html#cb191-5"></a>  <span class="dt">informationRates =</span> <span class="kw">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>),</span>
<span id="cb191-6"><a href="sequential.html#cb191-6"></a>  <span class="dt">typeOfDesign =</span> <span class="st">"P"</span></span>
<span id="cb191-7"><a href="sequential.html#cb191-7"></a>)</span>
<span id="cb191-8"><a href="sequential.html#cb191-8"></a></span>
<span id="cb191-9"><a href="sequential.html#cb191-9"></a><span class="kw">summary</span>(design)</span></code></pre></div>
<pre><code>## Sequential analysis with a maximum of 2 looks (group sequential design)
## 
## Stage                                   1      2 
## Information rate                      50%   100% 
## Efficacy boundary (z-value scale)   2.178  2.178 
## Cumulative alpha spent             0.0294 0.0500 
## Two-sided local significance level 0.0294 0.0294</code></pre>
<div class="sourceCode" id="cb193"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb193-1"><a href="sequential.html#cb193-1"></a>power_design &lt;-<span class="st"> </span><span class="kw">getSampleSizeMeans</span>(design,</span>
<span id="cb193-2"><a href="sequential.html#cb193-2"></a>  <span class="dt">alternative =</span> <span class="fl">0.5</span>,</span>
<span id="cb193-3"><a href="sequential.html#cb193-3"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>,</span>
<span id="cb193-4"><a href="sequential.html#cb193-4"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span></span>
<span id="cb193-5"><a href="sequential.html#cb193-5"></a>)</span>
<span id="cb193-6"><a href="sequential.html#cb193-6"></a></span>
<span id="cb193-7"><a href="sequential.html#cb193-7"></a><span class="kw">summary</span>(power_design)</span></code></pre></div>
<pre><code>## Sample size calculation for a continuous endpoint
## 
## Sequential analysis with a maximum of 2 looks (group sequential design).
## The sample size was calculated for a two-sample t-test (two-sided),
## alternative = 0.5, standard deviation = 1, allocation ratio = 1, and power 80%.
## 
## Stage                                         1      2 
## Information rate                            50%   100% 
## Efficacy boundary (z-value scale)         2.178  2.178 
## Number of subjects                           71    142 
## Cumulative alpha spent                   0.0294 0.0500 
## Cumulative power                         0.4638 0.8000 
## Two-sided local significance level       0.0294 0.0294 
## Lower efficacy boundary (t)              -0.529 -0.370 
## Upper efficacy boundary (t)               0.529  0.370 
## Exit probability for efficacy (under H0) 0.0294 
## Exit probability for efficacy (under H1) 0.4638 
## 
## Legend:
##   (t): approximate treatment effect scale</code></pre>
</div>
<div id="stopping-for-futility" class="section level2">
<h2>
<span class="header-section-number">14.5</span> Stopping for futility</h2>
<p>At an interim look, one might decide to stop a trial for <em>futility</em>.
At an interim look one can also calculate <em>conditional power</em>, or the probability to achieve a significant result, given the observed effect size, if one was to continue to the maximum sample size one is willing to collect.</p>
<p>Wassmer and Brannath write (section 7.2):</p>
<p>If the conditional power is inadequately small, then one could stop the trial for futility. This has been suggested by Halperin et al. (1982) and Lan et al. (1982) in the context of group sequential trials (for a review of related methods, see Lachin 2005). Due to the monotonicity of the conditional power in p1, stopping the trial if the conditional power is below a specific threshold cp0 is equivalent to stopping the trial if p1 is above some level <span class="math inline">\(\alpha_0\)</span>.</p>
<p>Jennison &amp; Turnball 2000 discuss equivalence tests in chapter 6. In formula 6.2 and 6.3 it seems they use beta to discuss incorrectly concluding equivalence when there is a true effect. They indeed mention some researchers would flip these 2 around (I would) but they keep the labels consistent with normal tests. This is useful and important in interpreting gsDesign!</p>
<p>They write: “The important point is that β in (6.2) represents the “consumer’s risk” since wrongly declaring equivalence may lead to an unsuitable preparation being allowed onto the market. Values of β and δ must be chosen to satisfy the appropriate regulatory agency. Recommended choices are often β = 0.05 and δ = log(1.25)"</p>
<p>First, we can stop for futility because the observed effect size is zero or in the wrong direction. This is only possible in a directional (one-sided) test. In other words, if we predict and effect larger than zero (e.g., d = 0.5), and we observe an effect ≤ 0, we might stop the data collection for <strong>futility</strong>. Note that it is perfectly possible, due to random variation, that we observe an effect size smaller than 0, especially in small noisy samples where the true effect size is large. But this simple stopping rule will illustrate the basic idea of stopping for futility.</p>
<p>Jennison &amp; Turnball: In view of the savings that can be achieved in
experimental costs and time, we would recommend that early stopping to accept
the null hypothesis be considered in any group sequential two-sided test.</p>
<p>Although the ethical motivation for stopping a clinical
c 2000 by Chapman &amp; Hall/CRC
trial early is greatest when a treatment difference is found and randomization of
patients to an inferior treatment can be avoided, there are sound financial reasons
to curtail a study when it is evident that there is no treatment difference to detect.
Moreover, such curtailment can benefit future patients by releasing experimental
resources for the earlier exploration of further promising treatments.
Gould &amp; Pecore (1982) note the importance of early stopping to accept the
null hypothesis, and Gould (1983) proposes a method of “abandoning lost causes”
in which early termination occurs only to accept H0.</p>
<div class="sourceCode" id="cb195"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb195-1"><a href="sequential.html#cb195-1"></a><span class="co"># Manually specified futility bounds</span></span>
<span id="cb195-2"><a href="sequential.html#cb195-2"></a>design &lt;-<span class="st"> </span><span class="kw">getDesignGroupSequential</span>(</span>
<span id="cb195-3"><a href="sequential.html#cb195-3"></a>  <span class="dt">sided =</span> <span class="dv">1</span>,</span>
<span id="cb195-4"><a href="sequential.html#cb195-4"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb195-5"><a href="sequential.html#cb195-5"></a>  <span class="dt">beta =</span> <span class="fl">0.1</span>,</span>
<span id="cb195-6"><a href="sequential.html#cb195-6"></a>  <span class="dt">informationRates =</span> <span class="kw">c</span>(<span class="fl">0.33</span>, <span class="fl">0.67</span>, <span class="dv">1</span>),</span>
<span id="cb195-7"><a href="sequential.html#cb195-7"></a>  <span class="dt">typeOfDesign =</span> <span class="st">"asOF"</span>,</span>
<span id="cb195-8"><a href="sequential.html#cb195-8"></a>  <span class="dt">futilityBounds =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>),</span>
<span id="cb195-9"><a href="sequential.html#cb195-9"></a>  <span class="dt">bindingFutility =</span> <span class="ot">FALSE</span></span>
<span id="cb195-10"><a href="sequential.html#cb195-10"></a>)</span>
<span id="cb195-11"><a href="sequential.html#cb195-11"></a></span>
<span id="cb195-12"><a href="sequential.html#cb195-12"></a><span class="kw">summary</span>(design)</span></code></pre></div>
<pre><code>## Sequential analysis with a maximum of 3 looks (group sequential design)
## 
## Stage                                   1      2      3 
## Information rate                      33%    67%   100% 
## Efficacy boundary (z-value scale)   3.218  2.134  1.696 
## Futility boundary (z-value scale)       0      0 
## Cumulative alpha spent             0.0006 0.0166 0.0500 
## One-sided local significance level 0.0006 0.0164 0.0450</code></pre>
<div class="sourceCode" id="cb197"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb197-1"><a href="sequential.html#cb197-1"></a><span class="co"># Formal beta spending function</span></span>
<span id="cb197-2"><a href="sequential.html#cb197-2"></a>design &lt;-<span class="st"> </span><span class="kw">getDesignGroupSequential</span>(</span>
<span id="cb197-3"><a href="sequential.html#cb197-3"></a>  <span class="dt">sided =</span> <span class="dv">1</span>,</span>
<span id="cb197-4"><a href="sequential.html#cb197-4"></a>  <span class="dt">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb197-5"><a href="sequential.html#cb197-5"></a>  <span class="dt">beta =</span> <span class="fl">0.05</span>,</span>
<span id="cb197-6"><a href="sequential.html#cb197-6"></a>  <span class="dt">informationRates =</span> <span class="kw">c</span>(<span class="fl">0.33</span>, <span class="fl">0.67</span>, <span class="dv">1</span>),</span>
<span id="cb197-7"><a href="sequential.html#cb197-7"></a>  <span class="dt">typeOfDesign =</span> <span class="st">"asOF"</span>,</span>
<span id="cb197-8"><a href="sequential.html#cb197-8"></a>  <span class="dt">typeBetaSpending=</span><span class="st">"bsOF"</span>,</span>
<span id="cb197-9"><a href="sequential.html#cb197-9"></a>  <span class="dt">bindingFutility =</span> <span class="ot">FALSE</span></span>
<span id="cb197-10"><a href="sequential.html#cb197-10"></a>)</span>
<span id="cb197-11"><a href="sequential.html#cb197-11"></a></span>
<span id="cb197-12"><a href="sequential.html#cb197-12"></a><span class="kw">summary</span>(design)</span></code></pre></div>
<pre><code>## Sequential analysis with a maximum of 3 looks (group sequential design)
## 
## Stage                                   1      2      3 
## Information rate                      33%    67%   100% 
## Efficacy boundary (z-value scale)   3.218  2.134  1.696 
## Futility boundary (z-value scale)  -1.284  0.623 
## Cumulative alpha spent             0.0006 0.0166 0.0500 
## One-sided local significance level 0.0006 0.0164 0.0450</code></pre>
<div class="sourceCode" id="cb199"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb199-1"><a href="sequential.html#cb199-1"></a><span class="kw">plot</span>(design)</span></code></pre></div>
<p><img src="Statistical_Inferences_files/figure-html/unnamed-chunk-79-1.png" width="672"></p>
<div class="sourceCode" id="cb200"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb200-1"><a href="sequential.html#cb200-1"></a>power_design &lt;-<span class="st"> </span><span class="kw">getSampleSizeMeans</span>(design,</span>
<span id="cb200-2"><a href="sequential.html#cb200-2"></a>  <span class="dt">alternative =</span> <span class="fl">0.5</span>,</span>
<span id="cb200-3"><a href="sequential.html#cb200-3"></a>  <span class="dt">stDev =</span> <span class="dv">1</span>,</span>
<span id="cb200-4"><a href="sequential.html#cb200-4"></a>  <span class="dt">allocationRatioPlanned =</span> <span class="dv">1</span></span>
<span id="cb200-5"><a href="sequential.html#cb200-5"></a>)</span>
<span id="cb200-6"><a href="sequential.html#cb200-6"></a></span>
<span id="cb200-7"><a href="sequential.html#cb200-7"></a><span class="kw">summary</span>(power_design)</span></code></pre></div>
<pre><code>## Sample size calculation for a continuous endpoint
## 
## Sequential analysis with a maximum of 3 looks (group sequential design).
## The sample size was calculated for a two-sample t-test (one-sided),
## alternative = 0.5, standard deviation = 1, allocation ratio = 1, and power 95%.
## 
## Stage                                         1      2      3 
## Information rate                            33%    67%   100% 
## Efficacy boundary (z-value scale)         3.218  2.134  1.696 
## Futility boundary (z-value scale)        -1.284  0.623 
## Number of subjects                           61    123    183 
## Cumulative alpha spent                   0.0006 0.0166 0.0500 
## Cumulative power                         0.0996 0.7339 0.9500 
## One-sided local significance level       0.0006 0.0164 0.0450 
## Efficacy boundary (t)                     0.871  0.390  0.252 
## Futility boundary (t)                    -0.334  0.113 
## Overall exit probability (under H0)      0.1003 0.6503 
## Overall exit probability (under H1)      0.1003 0.6503 
## Exit probability for efficacy (under H0) 0.0006 0.0160 
## Exit probability for efficacy (under H1) 0.0996 0.6343 
## Exit probability for futility (under H0) 0.0996 0.6343 
## Exit probability for futility (under H1) 0.0006 0.0160 
## 
## Legend:
##   (t): approximate treatment effect scale</code></pre>
<p>We briefly discuss this in our Second Generation P-Value paper as well, but for a test of superiority versus a one-sided test for equivalence.</p>
</div>
<div id="conditional-power" class="section level2">
<h2>
<span class="header-section-number">14.6</span> Conditional power</h2>
<p>7.4.1: Sometimes one can identify the smallest effect size that is considered clinically relevant or worthwhile to be identified in the clinical trial. Such minimal effect size is then used in the initial sample size calculation where we then aim to guarantee that the unconditional power is above some target value (for example, 90%). The concept of a minimal clinically relevant alternative can also be applied at the interim analysis in the conditional power and corresponding sample size calculation.</p>
<p>We believe that conditional power is a useful tool for decision making at the interim
analysis. The effect size used for the conditional power calculation, however, should
not always be considered a realistic estimate of the true effect size. It should rather
be triggered by the question of which effect sizes are considered worth the future
efforts of rejecting the null hypothesis at the end of the trial. Such worthy effect
sizes may be the same as at the beginning of the trial but may also change due to
new evidence on clinical relevance, safety, and cost from in and outside the trial</p>
<p><a href="https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-017-0387-4" class="uri">https://bmcmedresmethodol.biomedcentral.com/track/pdf/10.1186/s12874-017-0387-4</a></p>
<p>With respectto futility stopping, there are mainly two fundamentalapproaches in the statistical literature [3, 4]. The firstapproach is a conditional one, where the study is stoppedfor futility, if the conditional power falls under a prespec-ified threshold. This conditional approach can further bedivided into stochastic curtailment [5, 6], a frequentistapproach, and methods based on the predictive poweror the predictive probability [4], which are partially orfully Bayesian methods [7, 8].</p>
<p>In general, stopping for futility without compromisingthe type I error is possible at any time and indepen-dent of any predefined rules as an early acceptance ofH0decreases the actual type I error rate.</p>
<p>In the context ofgroup sequential designs, it can generally be differentiatedbetween binding and non-binding stopping for futilityrules, compare also Bretz et al [26]. ‘Binding’ means thatstopping for futility at the interim analysis is obligatorywhenever the futility criteria are met. When the data sug-gest stopping for futility, it is thusnotallowed to continuethe trial for other external reasons. If a binding futility ruleis applied, the local significance levels can be increased inorder to fully exhaust the global significance level whichis otherwise no longer guaranteed as futility stoppingimplies a lower probability of rejecting the null hypothe-sis. In contrast, the non-binding version does not commitearly futility stopping.</p>
<p>The ‘cumulative Type 1 error rate’ or ‘cumulative alpha spent’ at any look is the probability of rejecting H0 when it is true at or before that look. Therefore, at the last look the cumulative alpha spent will be equal to the alpha level.</p>
<p>Wassmer and Brannath, section 8.2.3, discuss the use of two-sided confidence intervals. They highlight an equivalence test as one case in which a two-sided confidence interval is computed. We specify an equivalence range with a lower and upper bound.</p>

</div>
</div></body></html>

<p style="text-align: center;">
<a href="bayes.html"><button class="btn btn-default">Previous</button></a>
<a href="references.html"><button class="btn btn-default">Next</button></a>
</p>
<p class="build-date">Page built: 
2020-08-07
</p>
</div>
</div>

<div class="row" style="padding-top: 2em;">
<p style="text-align: center">
<img src="images/logo.png" style="width: 100px; padding: 0; display: inline; vertical-align: top">
<span style="display: inline-block; margin-left: 2em; margin-top: 16px; font-size: small">
<span style="font-weight: bold;">Daniel Lakens</span><br/>
<a href="https://statistical-inferences.com">statistical-inferences.com</a><br/>
page built  2020-08-07 17:06:31
</span>
</p>
</div>


</body>
</html>
